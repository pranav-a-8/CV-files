{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T06:10:59.062203Z",
     "iopub.status.busy": "2025-11-10T06:10:59.061854Z",
     "iopub.status.idle": "2025-11-10T06:10:59.291230Z",
     "shell.execute_reply": "2025-11-10T06:10:59.290491Z",
     "shell.execute_reply.started": "2025-11-10T06:10:59.062176Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2 # OpenCV, which we will use for all the core image processing functions \n",
    "           # (like filtering and color space conversions)\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm # A progress bar\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the correct input and output folder paths\n",
    "input_folder = os.path.join('/kaggle/input/', 'trident', 'DATA', 'Icam')\n",
    "output_folder = os.path.join('/kaggle/working', 'trident', 'DATA', 'Iphy_enh')\n",
    "\n",
    "# Define the folder for transmission maps\n",
    "trans_map_folder = os.path.join('/kaggle/working', 'trident', 'DATA', 'classic_phy_mod_trans_map')\n",
    "\n",
    "# Automatically create the output folders if they don't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(trans_map_folder, exist_ok=True)\n",
    "\n",
    "# Check if the input path exists\n",
    "if not os.path.exists(input_folder):\n",
    "    print(f\"Error: Could not find the input dataset at: {input_folder}\")\n",
    "else:\n",
    "    print(f\"Input dataset found at: {input_folder}\")\n",
    "    print(f\"Output folder created at: {os.path.abspath(output_folder)}\")\n",
    "    print(f\"Transmission map folder created at: {os.path.abspath(trans_map_folder)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T06:10:59.292135Z",
     "iopub.status.busy": "2025-11-10T06:10:59.291938Z",
     "iopub.status.idle": "2025-11-10T06:10:59.309472Z",
     "shell.execute_reply": "2025-11-10T06:10:59.308757Z",
     "shell.execute_reply.started": "2025-11-10T06:10:59.292116Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Helper function for plotting (for final verification) \n",
    "def show_image(image, title='Image', cmap_type='viridis'):\n",
    "    \"\"\"\n",
    "    Helper function to display an image in a Jupyter Notebook.\n",
    "    Converts BGR to RGB for correct color display.\n",
    "    \"\"\"\n",
    "    # Check if the image is color (3 channels) or grayscale (1 channel)\n",
    "    if len(image.shape) == 3:\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        plt.imshow(image, cmap=cmap_type)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Step 1 Function \n",
    "def get_dark_channel(image, patch_size=15):\n",
    "    \"\"\"\n",
    "    Computes the Dark Channel Prior (DCP) of an image.\n",
    "    \"\"\"\n",
    "    # Find the minimum value across all 3 color channels (R, G, B) for each pixel\n",
    "    # This creates a 2D grayscale map\n",
    "    min_channel = image.min(axis=2)\n",
    "\n",
    "    # Define the 'patch' or 'window' as a kernel\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (patch_size, patch_size))\n",
    "    \n",
    "    # Apply the min filter over the 15x15 neighborhood\n",
    "    # cv2.erode() with this kernel finds the minimum value within the patch\n",
    "    dark_channel = cv2.erode(min_channel, kernel)\n",
    "    \n",
    "    return dark_channel\n",
    "\n",
    "# Step 2 Function \n",
    "def get_background_light(image, dark_channel, percentile=0.001):\n",
    "    \"\"\"\n",
    "    Estimates the background light (B) from the haziest 0.1% of pixels.\n",
    "    \"\"\"\n",
    "    # Get total number of pixels\n",
    "    num_pixels = dark_channel.size\n",
    "\n",
    "    # Calculate number of pixels to take for the top 0.1%\n",
    "    k = int(num_pixels * percentile)\n",
    "\n",
    "    # Flatten the dark channel to a 1D array\n",
    "    flat_dark_channel = dark_channel.flatten()\n",
    "    \n",
    "    # Find the indices of the brightest pixels (top k values) \n",
    "    # np.argsort sorts from low to high, so we take the last 'k' indices\n",
    "    indices = np.argsort(flat_dark_channel)[-k:]\n",
    "\n",
    "    # Convert 1D indices back to 2D (row, col) coordinates\n",
    "    rows, cols = np.unravel_index(indices, dark_channel.shape)\n",
    "    \n",
    "    # Get the B, G, R values from the original image at these locations\n",
    "    hazy_pixels = image[rows, cols]\n",
    "\n",
    "    # Average these pixels values across each channel (B, G, R)\n",
    "    background_light = np.mean(hazy_pixels, axis=0)\n",
    "    \n",
    "    return background_light\n",
    "\n",
    "# Step 3 Function \n",
    "def get_transmission_map(image, background_light, patch_size=15, omega=0.95):\n",
    "    \"\"\"\n",
    "    Calculates the transmission map t(x).\n",
    "    \"\"\"\n",
    "    # Normalize the image by the background light\n",
    "    # Using np.clip to avoid division by zero if B is 0 in a channel\n",
    "    normalized_image = image / np.clip(background_light, 1e-6, 255.0)\n",
    "\n",
    "    # Get the dark channel of this normalized image\n",
    "    normalized_dark_channel = get_dark_channel(normalized_image, patch_size)\n",
    "    \n",
    "    # Calculate the transmission map using the formula \n",
    "    # omega is set to 0.95 to keep some haze\n",
    "    transmission_map = 1 - (omega * normalized_dark_channel)\n",
    "    \n",
    "    return transmission_map\n",
    "\n",
    "# Step 4 Function \n",
    "def recover_radiance(image, background_light, transmission_map, t0=0.1):\n",
    "    \"\"\"\n",
    "    Recovers the scene radiance J(x) using the main dehazing formula.\n",
    "    \"\"\"\n",
    "    # Clamp the transmission map with t0 = 0.1\n",
    "    clamped_transmission = np.maximum(transmission_map, t0)\n",
    "    \n",
    "    # Expand transmission map from 2D (256x256) to 3D (256x256x1)\n",
    "    # This allows it to be divided from the 3-channel image (256x256x3)\n",
    "    transmission_3d = clamped_transmission[..., None]\n",
    "\n",
    "    # Implement the radiance recovery formula\n",
    "    numerator = image - background_light # (I(x) - B)\n",
    "    J_partial = numerator / transmission_3d # (I(x) - B)/max(t(x), t0)\n",
    "    J = J_partial + background_light # ((I(x) - B)/max(t(x), t0)) + B\n",
    "    \n",
    "    return J\n",
    "\n",
    "# Step 5 Functions \n",
    "def get_compensation_factor(background_light):\n",
    "    \"\"\"\n",
    "    Calculates the adaptive compensation factor based on the B vector.\n",
    "    \"\"\"\n",
    "    # Get B, G, R values (OpenCV is BGR)\n",
    "    B_b, B_g, B_r = background_light\n",
    "\n",
    "    # Calculate average of \"problem\" colors (G and B)\n",
    "    avg_bg = (B_g + B_b) / 2\n",
    "\n",
    "    # Find Red_Ratio\n",
    "    # Adding 1e-6 to avoid division by zero\n",
    "    red_ratio = B_r / (avg_bg + 1e-6)\n",
    "\n",
    "    # Apply the adaptive logic\n",
    "    if red_ratio < 0.7:\n",
    "        factor = 0.5 # Very strong blue cast\n",
    "    elif red_ratio < 0.85:\n",
    "        factor = 0.4 # Moderate cast\n",
    "    else:\n",
    "        factor = 0.3 # Mild cast\n",
    "        \n",
    "    return factor\n",
    "\n",
    "def apply_red_compensation(image, background_light):\n",
    "    \"\"\"\n",
    "    Applies the adaptive red channel compensation.\n",
    "    \"\"\"\n",
    "    # Get the adaptive factor\n",
    "    compensation_factor = get_compensation_factor(background_light)\n",
    "\n",
    "    # Get the Red channel (index 2 for BGR)\n",
    "    # We must work with a float copy to avoid data type errors\n",
    "    image_float = image.astype(float)\n",
    "    red_channel = image_float[..., 2]\n",
    "\n",
    "    # Apply the boost formula\n",
    "    red_enhanced = red_channel * (1 + compensation_factor)\n",
    "    \n",
    "    # Clip the enhanced red channel to not exceed 255\n",
    "    red_enhanced_clipped = np.clip(red_enhanced, 0, 255)\n",
    "\n",
    "    # Put the enhanced channel back into the image\n",
    "    compensated_image = image_float.copy()\n",
    "    compensated_image[..., 2] = red_enhanced_clipped\n",
    "\n",
    "    # Convert back to uint8\n",
    "    return compensated_image.astype(np.uint8)\n",
    "\n",
    "# Step 6 Function\n",
    "def apply_clahe(image, clip_limit=2.0, tile_size=(8, 8)):\n",
    "    \"\"\"\n",
    "    Applies CLAHE to the L (Lightness/brightness) channel (0 = black, max = white) of an image.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Convert the BGR image to Lab color space\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2Lab)\n",
    "    \n",
    "    # Split the Lab image into L, a, and b channels\n",
    "    # 'L' is Lightness (brightness), 'a' and 'b' are color channels\n",
    "    l_channel, a_channel, b_channel = cv2.split(lab_image)\n",
    "\n",
    "    # Create a CLAHE object \n",
    "    # We use the 8x8 grid size \n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_size)\n",
    "    \n",
    "    # Apply CLAHE to the L-channel only\n",
    "    l_channel_enhanced = clahe.apply(l_channel)\n",
    "\n",
    "    # Merge the enhanced L-channel back with the original a and b channels\n",
    "    lab_enhanced = cv2.merge((l_channel_enhanced, a_channel, b_channel))\n",
    "    \n",
    "    # Convert the Lab image back to BGR\n",
    "    final_image = cv2.cvtColor(lab_enhanced, cv2.COLOR_Lab2BGR)\n",
    "    \n",
    "    return final_image\n",
    "\n",
    "def plot_on_ax(ax, image, title, cmap_type='viridis'):\n",
    "    \"\"\"\n",
    "    Helper function to plot an image on a specific Matplotlib axis (subplot).\n",
    "    \"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        # Convert BGR to RGB\n",
    "        ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        # Show grayscale\n",
    "        ax.imshow(image, cmap=cmap_type)\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "\n",
    "print(\"All processing functions are defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T06:10:59.311437Z",
     "iopub.status.busy": "2025-11-10T06:10:59.311199Z",
     "iopub.status.idle": "2025-11-10T06:11:51.006481Z",
     "shell.execute_reply": "2025-11-10T06:11:51.005415Z",
     "shell.execute_reply.started": "2025-11-10T06:10:59.311416Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Main Processing Loop \n",
    "\n",
    "# SET THE PROCESSING RANGE HERE \n",
    "START_NUMBER = 12001\n",
    "END_NUMBER = 13000\n",
    "FILE_EXTENSION = '.png'  # Change to '.jpg' or '.jpeg' if needed\n",
    "\n",
    "print(f\"Starting processing from {START_NUMBER}{FILE_EXTENSION} to {END_NUMBER}{FILE_EXTENSION}...\")\n",
    "\n",
    "# Loop through the specified number range, with a progress bar\n",
    "for i in tqdm(range(START_NUMBER, END_NUMBER + 1), desc='Processing Images'):\n",
    "    try:\n",
    "        # Construct the filename and paths\n",
    "        filename = f\"{i}{FILE_EXTENSION}\"\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        \n",
    "        # Construct the output path for the transmission map\n",
    "        trans_map_path = os.path.join(trans_map_folder, filename)\n",
    "\n",
    "        # Check if the input file actually exists\n",
    "        if not os.path.exists(image_path):\n",
    "            # If the file doesn't exist, skip it\n",
    "            continue\n",
    "\n",
    "        # Load Image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Warning: Could not read {image_path}. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        # Resize and Convert\n",
    "        input_image = cv2.resize(image, (256, 256))\n",
    "        input_image_float = input_image.astype(float)\n",
    "        \n",
    "        # Run Full Stage 1 Pipeline\n",
    "        \n",
    "        # Step 1: Dark Channel\n",
    "        dark_channel_map = get_dark_channel(input_image_float, patch_size=15)\n",
    "        \n",
    "        # Step 2: Background Light\n",
    "        background_light_B = get_background_light(input_image_float, dark_channel_map)\n",
    "        \n",
    "        # Step 3: Transmission Map\n",
    "        transmission_map_t = get_transmission_map(input_image_float, background_light_B, patch_size=15, omega=0.95)\n",
    "        \n",
    "        # Scale the 0.0-1.0 map to 0-255 and save it as an 8-bit image\n",
    "        transmission_map_image = (transmission_map_t * 255).astype(np.uint8)\n",
    "        cv2.imwrite(trans_map_path, transmission_map_image)\n",
    "        \n",
    "        # Step 4: Recover Radiance\n",
    "        dehazed_image_J = recover_radiance(input_image_float, background_light_B, transmission_map_t, t0=0.1)\n",
    "        dehazed_image_J_uint8 = np.clip(dehazed_image_J, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        # Step 5: Red Compensation\n",
    "        compensated_image = apply_red_compensation(dehazed_image_J_uint8, background_light_B)\n",
    "        \n",
    "        # Step 6: CLAHE\n",
    "        final_enhanced_image = apply_clahe(compensated_image, clip_limit=2.0, tile_size=(8, 8))\n",
    "        \n",
    "        # Save the Result \n",
    "        cv2.imwrite(output_path, final_enhanced_image)\n",
    "        \n",
    "    except Exception as error:\n",
    "        print(f\"Error processing {image_path}: {error}\")\n",
    "\n",
    "print(\"Batch processing complete!\")\n",
    "print(f\"All enhanced images are saved in: {os.path.abspath(output_folder)}\")\n",
    "print(f\"All transmission maps are saved in: {os.path.abspath(trans_map_folder)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T06:11:51.007974Z",
     "iopub.status.busy": "2025-11-10T06:11:51.007613Z",
     "iopub.status.idle": "2025-11-10T06:11:53.079315Z",
     "shell.execute_reply": "2025-11-10T06:11:53.078083Z",
     "shell.execute_reply.started": "2025-11-10T06:11:51.007943Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell: Verify one of the results (Step-by-Step) AND Plot Comparison\n",
    "# (This cell runs the full pipeline and the 1x3 comparison plot at the end)\n",
    "\n",
    "# SET YOUR TEST NUMBER HERE\n",
    "TEST_NUMBER = 21252\n",
    "FILE_EXTENSION = '.png'\n",
    "\n",
    "filename = f\"{TEST_NUMBER}{FILE_EXTENSION}\"\n",
    "\n",
    "# Define BOTH root paths\n",
    "input_folder = os.path.join('/kaggle/input/', 'trident', 'DATA', 'Icam')\n",
    "ref_folder = os.path.join('/kaggle/input/', 'trident', 'DATA', 'Iclean') \n",
    "\n",
    "original_path = os.path.join(input_folder, filename)\n",
    "ref_path = os.path.join(ref_folder, filename) \n",
    "\n",
    "# Check if BOTH files exist\n",
    "if os.path.exists(original_path) and os.path.exists(ref_path):\n",
    "    # Load and Prepare Original Image\n",
    "    original_test = cv2.imread(original_path)\n",
    "    original_resized = cv2.resize(original_test, (256, 256))\n",
    "    original_resized_float = original_resized.astype(float)\n",
    "    \n",
    "    # Load and Prepare Reference Image \n",
    "    ref_test = cv2.imread(ref_path)\n",
    "    ref_resized = cv2.resize(ref_test, (256, 256))\n",
    "    \n",
    "    print(f\"--- Running full pipeline for {filename} ---\")\n",
    "\n",
    "    # Re-run the pipeline step-by-step \n",
    "    \n",
    "    # Step 1: Dark Channel\n",
    "    dark_channel_map = get_dark_channel(original_resized_float, patch_size=15)\n",
    "    \n",
    "    # Step 2: Background Light\n",
    "    background_light_B = get_background_light(original_resized_float, dark_channel_map)\n",
    "    print(f\"Step 2: Background Light (B) Vector = {background_light_B}\")\n",
    "    \n",
    "    # Step 3: Transmission Map\n",
    "    transmission_map_t = get_transmission_map(original_resized_float, background_light_B, patch_size=15, omega=0.95)\n",
    "    # Convert for display (0.0-1.0 -> 0-255)\n",
    "    trans_map_display = (transmission_map_t * 255).astype(np.uint8)\n",
    "    \n",
    "    # Step 4: Recover Radiance\n",
    "    dehazed_image_J = recover_radiance(original_resized_float, background_light_B, transmission_map_t, t0=0.1)\n",
    "    dehazed_image_J_uint8 = np.clip(dehazed_image_J, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Step 5: Red Compensation\n",
    "    compensated_image = apply_red_compensation(dehazed_image_J_uint8, background_light_B)\n",
    "    \n",
    "    # Step 6: CLAHE\n",
    "    final_enhanced_image = apply_clahe(compensated_image, clip_limit=2.0, tile_size=(8, 8))\n",
    "    \n",
    "    print(\"--- Plotting all 6 visual steps ---\")\n",
    "\n",
    "    # Create the 2x3 plot\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10)) # 2 rows, 3 columns\n",
    "    \n",
    "    # Plot 1: Original Image\n",
    "    plot_on_ax(axes[0, 0], original_resized, title='(0) Original Input')\n",
    "    \n",
    "    # Plot 2: Dark Channel Map\n",
    "    plot_on_ax(axes[0, 1], dark_channel_map, title='(1) Dark Channel Map', cmap_type='gray')\n",
    "    \n",
    "    # Plot 3: Transmission Map\n",
    "    plot_on_ax(axes[0, 2], trans_map_display, title='(3) Transmission Map', cmap_type='gray')\n",
    "    \n",
    "    # Plot 4: Dehazed Image \n",
    "    plot_on_ax(axes[1, 0], dehazed_image_J_uint8, title='(4) Dehazed (Radiance Recovered)')\n",
    "    \n",
    "    # Plot 5: Red Compensated Image \n",
    "    plot_on_ax(axes[1, 1], compensated_image, title='(5) Red Compensated')\n",
    "    \n",
    "    # Plot 6: Final Enhanced Image \n",
    "    plot_on_ax(axes[1, 2], final_enhanced_image, title='(6) Final Enhanced (CLAHE)')\n",
    "    \n",
    "    # Add the title and show the figure\n",
    "    fig.suptitle(f\"Step-by-Step Verification for: {filename}\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to make room for suptitle\n",
    "    plt.show() \n",
    "    \n",
    "    \n",
    "    print(f\"--- Plotting Final Comparison for {filename} ---\")\n",
    "\n",
    "    # Create the 1x3 plot\n",
    "    fig_comp, axes_comp = plt.subplots(1, 3, figsize=(18, 6)) \n",
    "    \n",
    "    # Plot 1: Original Image\n",
    "    plot_on_ax(axes_comp[0], original_resized, title=f'Input (I_cam: {filename})')\n",
    "    \n",
    "    # Plot 2: Classical Output\n",
    "    plot_on_ax(axes_comp[1], final_enhanced_image, title='Classical Output (Final)')\n",
    "    \n",
    "    # Plot 3: Ground Truth\n",
    "    plot_on_ax(axes_comp[2], ref_resized, title=f'Ground Truth (I_clean: {filename})')\n",
    "    \n",
    "    fig_comp.suptitle(f\"Classical Method Verification for: {filename}\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) \n",
    "    plt.show() \n",
    "    \n",
    "else:\n",
    "    # Error message if file is missing\n",
    "    print(f\"Error: Could not find '{filename}'.\")\n",
    "    print(f\"Please check that it exists in: {original_path} AND {ref_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T06:13:49.514758Z",
     "iopub.status.busy": "2025-11-10T06:13:49.513600Z",
     "iopub.status.idle": "2025-11-10T06:14:34.063702Z",
     "shell.execute_reply": "2025-11-10T06:14:34.062581Z",
     "shell.execute_reply.started": "2025-11-10T06:13:49.514715Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Calculate Classical Model Metrics\n",
    "# This cell loads the pre-computed classical results from 'output_folder'\n",
    "# and compares them to the ground truth to get the average SSIM and PSNR.\n",
    "\n",
    "# Install/Import dependencies\n",
    "!pip install -q scikit-image tqdm\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from tqdm.auto import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the range of test images to evaluate\n",
    "# This should match the START_NUMBER and END_NUMBER from processing cell\n",
    "TEST_RANGE_STR = f\"{START_NUMBER}-{END_NUMBER}\"\n",
    "\n",
    "# Helper to parse the range \n",
    "def parse_range_string(range_str):\n",
    "    ids = []\n",
    "    for part in range_str.split(','):\n",
    "        part = part.strip()\n",
    "        if '-' in part:\n",
    "            start, end = part.split('-')\n",
    "            ids.extend(list(range(int(start), int(end) + 1)))\n",
    "        else:\n",
    "            ids.append(int(part))\n",
    "    return ids\n",
    "\n",
    "# Main Evaluation Loop \n",
    "image_ids = parse_range_string(TEST_RANGE_STR)\n",
    "ssim_scores = []\n",
    "psnr_scores = []\n",
    "\n",
    "print(f\"--- Starting Classical Model Evaluation ---\")\n",
    "print(f\"Loading {len(image_ids)} images from range {TEST_RANGE_STR}...\")\n",
    "\n",
    "# Wrap the loop with tqdm for a progress bar\n",
    "for img_id in tqdm(image_ids):\n",
    "    img_name = f\"{img_id}.png\"\n",
    "    \n",
    "    # Define paths to the final output and the ground truth\n",
    "    path_pred = os.path.join(output_folder, img_name)\n",
    "    path_ref = os.path.join(ref_folder, img_name)\n",
    "\n",
    "    if not os.path.exists(path_pred) or not os.path.exists(path_ref):\n",
    "        # print(f\"Warning: Skipping {img_id}, file not found.\")\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        # 1. Load images\n",
    "        I_pred_bgr = cv2.imread(path_pred)\n",
    "        I_ref_bgr = cv2.imread(path_ref)\n",
    "\n",
    "        # 2. Resize (just in case)\n",
    "        I_pred_resized = cv2.resize(I_pred_bgr, (256, 256))\n",
    "        I_ref_resized = cv2.resize(I_ref_bgr, (256, 256))\n",
    "        \n",
    "        # 3. Calculate Metrics\n",
    "        val_psnr = psnr(I_ref_resized, I_pred_resized, data_range=255)\n",
    "        val_ssim = ssim(I_ref_resized, I_pred_resized, multichannel=True, data_range=255, channel_axis=2)\n",
    "        \n",
    "        # 4. Store scores\n",
    "        psnr_scores.append(val_psnr)\n",
    "        ssim_scores.append(val_ssim)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {img_id}: {e}\")\n",
    "        \n",
    "# Print Final Results \n",
    "avg_psnr = np.mean(psnr_scores)\n",
    "avg_ssim = np.mean(ssim_scores)\n",
    "\n",
    "print(\"\\n--- Classical Model Evaluation Complete ---\")\n",
    "print(f\"Evaluated on {len(ssim_scores)} images from '{output_folder}'.\")\n",
    "print(f\"Average PSNR: {avg_psnr:.2f} dB\")\n",
    "print(f\"Average SSIM: {avg_ssim:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T06:14:44.250731Z",
     "iopub.status.busy": "2025-11-10T06:14:44.250399Z",
     "iopub.status.idle": "2025-11-10T06:14:51.483334Z",
     "shell.execute_reply": "2025-11-10T06:14:51.482157Z",
     "shell.execute_reply.started": "2025-11-10T06:14:44.250707Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the paths to your output folders\n",
    "folder_to_zip1 = '/kaggle/working/trident/DATA/Iphy_enh'\n",
    "folder_to_zip2 = '/kaggle/working/trident/DATA/classic_phy_mod_trans_map'\n",
    "\n",
    "# Define the names for your zip files\n",
    "zip_file_name1 = 'Iphy_enh.zip'\n",
    "zip_file_name2 = 'classic_phy_mod_trans_map.zip'\n",
    "\n",
    "print(f\"Zipping {folder_to_zip1}...\")\n",
    "# Use the 'zip' command: -r (recursive), -q (quiet, less console spam)\n",
    "# The first path is the output zip file\n",
    "# The second path is the folder you want to zip\n",
    "!zip -r -q {zip_file_name1} {folder_to_zip1}\n",
    "\n",
    "print(f\"Zipping {folder_to_zip2}...\")\n",
    "!zip -r -q {zip_file_name2} {folder_to_zip2}\n",
    "\n",
    "print(\"--- Zipping Complete! ---\")\n",
    "print(f\"Look for '{zip_file_name1}' and '{zip_file_name2}' in the '/kaggle/working/' directory.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8545778,
     "sourceId": 13481855,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
