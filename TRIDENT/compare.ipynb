{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "799523cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Part 1 script loaded - Continue to Part 2 for Physics models\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Underwater Image Denoising Model Comparison - Part 1: Calculate Metrics\n",
    "Compares 4 base models (attention, classical_physics, phy_head_v2, phy_head_v3)\n",
    "and 2 post-processed variants (attention+CLAHE+RedBoost, phy_head_v3+CLAHE+RedBoost)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "CFG = {\n",
    "    \"data\": {\n",
    "        \"root_cam\": \"D:/ML_works/TRIDENT/DATA/Icam\",\n",
    "        \"root_ref\": \"D:/ML_works/TRIDENT/DATA/Iclean\",\n",
    "        \"img_size\": 256,\n",
    "    },\n",
    "    \"checkpoints\": {\n",
    "        \"attention\": \"Attention/best_weights_epoch_041.pth\",\n",
    "        \"phy_v2\": \"physics_encoder/checkpointsphy/best_v2.pt\",\n",
    "        \"phy_v3\": \"physics_encoder/checkpointsphy/best_v3.pt\"\n",
    "    },\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"batch_size\": 16,  # Reduced for 8GB VRAM\n",
    "    \"results_dir\": \"comparison_results\"\n",
    "}\n",
    "\n",
    "os.makedirs(CFG[\"results_dir\"], exist_ok=True)\n",
    "\n",
    "# ============================================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def to_linear(img_srgb: torch.Tensor, gamma: float = 2.2) -> torch.Tensor:\n",
    "    return torch.clamp(img_srgb, 0.0, 1.0).pow(gamma)\n",
    "\n",
    "def to_srgb(img_lin: torch.Tensor, gamma: float = 2.2) -> torch.Tensor:\n",
    "    return torch.clamp(img_lin, 0.0, 1.0).pow(1.0 / gamma)\n",
    "\n",
    "def clamp01(x: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.clamp(x, 0.0, 1.0)\n",
    "\n",
    "def calculate_psnr(img1, img2):\n",
    "    \"\"\"Calculate PSNR between two images (0-1 range)\"\"\"\n",
    "    mse = F.mse_loss(img1, img2)\n",
    "    if mse < 1e-10:\n",
    "        return 100.0\n",
    "    return 20 * torch.log10(1.0 / torch.sqrt(mse)).item()\n",
    "\n",
    "def calculate_ssim(img1, img2, window_size=11):\n",
    "    \"\"\"Calculate SSIM between two images\"\"\"\n",
    "    C1 = 0.01 ** 2\n",
    "    C2 = 0.03 ** 2\n",
    "    \n",
    "    mu1 = F.avg_pool2d(img1, window_size, stride=1, padding=window_size // 2)\n",
    "    mu2 = F.avg_pool2d(img2, window_size, stride=1, padding=window_size // 2)\n",
    "    \n",
    "    mu1_sq = mu1 ** 2\n",
    "    mu2_sq = mu2 ** 2\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "    \n",
    "    sigma1_sq = F.avg_pool2d(img1 * img1, window_size, stride=1, padding=window_size // 2) - mu1_sq\n",
    "    sigma2_sq = F.avg_pool2d(img2 * img2, window_size, stride=1, padding=window_size // 2) - mu2_sq\n",
    "    sigma12 = F.avg_pool2d(img1 * img2, window_size, stride=1, padding=window_size // 2) - mu1_mu2\n",
    "    \n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / \\\n",
    "               ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "    \n",
    "    return ssim_map.mean().item()\n",
    "\n",
    "# ============================================================================\n",
    "# POST-PROCESSING FUNCTIONS (CLAHE + Red Boost)\n",
    "# ============================================================================\n",
    "\n",
    "def clahe_enhancement(img_tensor):\n",
    "    \"\"\"Apply CLAHE to tensor image (B, C, H, W) in [0, 1] range\"\"\"\n",
    "    device = img_tensor.device\n",
    "    img_np = (img_tensor.cpu().numpy() * 255).astype(np.uint8)\n",
    "    \n",
    "    batch_size = img_np.shape[0]\n",
    "    enhanced = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        img = img_np[i].transpose(1, 2, 0)  # CHW -> HWC\n",
    "        lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        \n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        l_clahe = clahe.apply(l)\n",
    "        \n",
    "        lab_clahe = cv2.merge((l_clahe, a, b))\n",
    "        rgb_clahe = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2RGB)\n",
    "        \n",
    "        enhanced.append(rgb_clahe.transpose(2, 0, 1))  # HWC -> CHW\n",
    "    \n",
    "    enhanced = np.stack(enhanced, axis=0)\n",
    "    return torch.from_numpy(enhanced / 255.0).float().to(device)\n",
    "\n",
    "def adaptive_red_boost(img_tensor):\n",
    "    \"\"\"Apply adaptive red channel boost to tensor image\"\"\"\n",
    "    device = img_tensor.device\n",
    "    img_np = (img_tensor.cpu().numpy() * 255).astype(np.uint8)\n",
    "    \n",
    "    batch_size = img_np.shape[0]\n",
    "    boosted = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        img = img_np[i].transpose(1, 2, 0)  # CHW -> HWC\n",
    "        \n",
    "        r_mean = img[:, :, 0].mean()\n",
    "        g_mean = img[:, :, 1].mean()\n",
    "        b_mean = img[:, :, 2].mean()\n",
    "        \n",
    "        if r_mean < 1:\n",
    "            factor = 2.0\n",
    "        else:\n",
    "            factor = (g_mean + b_mean) / (2 * r_mean)\n",
    "        factor = np.clip(factor, 1.2, 3.0)\n",
    "        \n",
    "        img_float = img.astype(np.float32)\n",
    "        img_float[:, :, 0] = np.clip(img_float[:, :, 0] * factor, 0, 255)\n",
    "        \n",
    "        boosted.append(img_float.astype(np.uint8).transpose(2, 0, 1))\n",
    "    \n",
    "    boosted = np.stack(boosted, axis=0)\n",
    "    return torch.from_numpy(boosted / 255.0).float().to(device)\n",
    "\n",
    "def compute_classical(I_cam_srgb):\n",
    "    \"\"\"Apply classical enhancement (CLAHE + Red Boost) to the input sRGB image\"\"\"\n",
    "    # Input is (B, C, H, W) sRGB tensor in [0, 1] range\n",
    "    temp_srgb = clahe_enhancement(I_cam_srgb)\n",
    "    enhanced_srgb = adaptive_red_boost(temp_srgb)\n",
    "    return enhanced_srgb\n",
    "\n",
    "# ============================================================================\n",
    "# DATASET\n",
    "# ============================================================================\n",
    "\n",
    "# ============================================================================\n",
    "# DATASET\n",
    "# ============================================================================\n",
    "\n",
    "class FullDataset(Dataset):\n",
    "    \"\"\"Load all images from Icam and Iclean folders\"\"\"\n",
    "    def __init__(self, root_cam, root_ref, img_size=256):\n",
    "        self.root_cam = root_cam\n",
    "        self.root_ref = root_ref\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        # Get all image files\n",
    "        cam_files = sorted([f for f in os.listdir(root_cam) if f.endswith('.png')])\n",
    "        ref_files = sorted([f for f in os.listdir(root_ref) if f.endswith('.png')])\n",
    "        \n",
    "        # Find common files\n",
    "        common = sorted(list(set(cam_files) & set(ref_files)))\n",
    "        \n",
    "        self.entries = []\n",
    "        for fname in common:\n",
    "            cam_path = os.path.join(root_cam, fname)\n",
    "            ref_path = os.path.join(root_ref, fname)\n",
    "            if os.path.exists(cam_path) and os.path.exists(ref_path):\n",
    "                self.entries.append((cam_path, ref_path, fname))\n",
    "        \n",
    "        print(f\"Found {len(self.entries)} image pairs\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.entries)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        cam_path, ref_path, fname = self.entries[idx]\n",
    "        \n",
    "        cam = Image.open(cam_path).convert(\"RGB\")\n",
    "        ref = Image.open(ref_path).convert(\"RGB\")\n",
    "        \n",
    "        cam = cam.resize((self.img_size, self.img_size), Image.BILINEAR)\n",
    "        ref = ref.resize((self.img_size, self.img_size), Image.BILINEAR)\n",
    "        \n",
    "        from torchvision import transforms\n",
    "        to_tensor = transforms.ToTensor()\n",
    "        \n",
    "        cam_srgb = to_tensor(cam)\n",
    "        ref_srgb = to_tensor(ref)\n",
    "        \n",
    "        cam_lin = to_linear(cam_srgb, 2.2)\n",
    "        ref_lin = to_linear(ref_srgb, 2.2)\n",
    "        \n",
    "        return {\n",
    "            \"I_cam_srgb\": cam_srgb,\n",
    "            \"I_cam_lin\": cam_lin,\n",
    "            \"I_clean_srgb\": ref_srgb,\n",
    "            \"I_clean_lin\": ref_lin,\n",
    "            \"filename\": fname\n",
    "        }\n",
    "\n",
    "# ============================================================================\n",
    "# ATTENTION MODEL (ResNet34 U-Net with CBAM)\n",
    "# ============================================================================\n",
    "\n",
    "class ChannelAttention_v1(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels // reduction, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(channels // reduction, channels, 1, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg = self.fc(self.avg_pool(x))\n",
    "        mx = self.fc(self.max_pool(x))\n",
    "        return x * self.sigmoid(avg + mx)\n",
    "\n",
    "class SpatialAttention_v1(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg = torch.mean(x, dim=1, keepdim=True)\n",
    "        mx, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        cat = torch.cat([avg, mx], dim=1)\n",
    "        return x * self.sigmoid(self.conv(cat))\n",
    "class CBAM_v1(nn.Module):\n",
    "    def __init__(self, channels, reduction=16, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention_v1(channels, reduction)  # <-- Change this\n",
    "        self.sa = SpatialAttention_v1(kernel_size)         # <-- Change this\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sa(self.ca(x))\n",
    "\n",
    "class ResNet34_UNet_CBAM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        from torchvision import models\n",
    "        resnet = models.resnet34(weights=None)\n",
    "        \n",
    "        self.conv1 = resnet.conv1\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        self.maxpool = resnet.maxpool\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.layer3 = resnet.layer3\n",
    "        self.layer4 = resnet.layer4\n",
    "        \n",
    "        self.cbam = CBAM_v1(channels=512, reduction=16, kernel_size=7)\n",
    "        \n",
    "        def conv_block(in_c, out_c):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_c, out_c, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(out_c),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout2d(p=0.1)\n",
    "            )\n",
    "        \n",
    "        self.up3 = conv_block(512 + 256, 256)\n",
    "        self.up2 = conv_block(256 + 128, 128)\n",
    "        self.up1 = conv_block(128 + 64, 64)\n",
    "        self.up0 = conv_block(64 + 64, 64)\n",
    "        self.up_final = conv_block(64, 64)\n",
    "        self.final_conv = nn.Conv2d(64, 3, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.relu(self.bn1(self.conv1(x)))\n",
    "        x1 = self.layer1(self.maxpool(x0))\n",
    "        x2 = self.layer2(x1)\n",
    "        x3 = self.layer3(x2)\n",
    "        x4 = self.layer4(x3)\n",
    "        \n",
    "        z = self.cbam(x4)\n",
    "        \n",
    "        u3 = F.interpolate(z, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        u3 = self.up3(torch.cat([u3, x3], dim=1))\n",
    "        \n",
    "        u2 = F.interpolate(u3, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        u2 = self.up2(torch.cat([u2, x2], dim=1))\n",
    "        \n",
    "        u1 = F.interpolate(u2, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        u1 = self.up1(torch.cat([u1, x1], dim=1))\n",
    "        \n",
    "        u0 = F.interpolate(u1, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        u0 = self.up0(torch.cat([u0, x0], dim=1))\n",
    "        \n",
    "        uF = F.interpolate(u0, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        uF = self.up_final(uF)\n",
    "        \n",
    "        return torch.sigmoid(self.final_conv(uF))\n",
    "\n",
    "print(\"✓ Part 1 script loaded - Continue to Part 2 for Physics models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2ad5d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Part 2 loaded - Continue to Part 3 for remaining metrics\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Part 2: Physics Models and Metrics Calculation\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# V3-COMPATIBLE CBAM MODULES (Final version)\n",
    "# These definitions force layer names to be indices to match phy_v3.pt\n",
    "# ============================================================================\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        # These modules are registered by index, not name\n",
    "        self.add_module(\"0\", nn.AdaptiveAvgPool2d(1))\n",
    "        self.add_module(\"1\", nn.Conv2d(channels, channels // reduction, 1, bias=True))\n",
    "        self.add_module(\"2\", nn.ReLU())\n",
    "        self.add_module(\"3\", nn.Conv2d(channels // reduction, channels, 1, bias=True))\n",
    "        self.add_module(\"4\", nn.Sigmoid())\n",
    "        self.add_module(\"5\", nn.AdaptiveMaxPool2d(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # We access the layers by their forced index names\n",
    "        avg_out = self._modules[\"3\"](self._modules[\"2\"](self._modules[\"1\"](self._modules[\"0\"](x))))\n",
    "        max_out = self._modules[\"3\"](self._modules[\"2\"](self._modules[\"1\"](self._modules[\"5\"](x))))\n",
    "        # Note: self._modules[\"4\"] is the sigmoid\n",
    "        return x * self._modules[\"4\"](avg_out + max_out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        # These modules are registered by index\n",
    "        self.add_module(\"0\", nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=True))\n",
    "        self.add_module(\"1\", nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg = torch.mean(x, dim=1, keepdim=True)\n",
    "        mx, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        cat = torch.cat([avg, mx], dim=1)\n",
    "        # Access by index name\n",
    "        return x * self._modules[\"1\"](self._modules[\"0\"](cat))\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, channels, reduction=16, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(channels, reduction)\n",
    "        self.sa = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sa(self.ca(x))\n",
    "\n",
    "# ============================================================================\n",
    "# PHYSICS ENCODER MODELS (v2 and v3)\n",
    "# ============================================================================\n",
    "\n",
    "# ============================================================================\n",
    "# PHYSICS ENCODER MODELS (v2 and v3)\n",
    "# ============================================================================\n",
    "\n",
    "def gn(num_channels, groups=8):\n",
    "# ... (rest of your script) ...\n",
    "    g = min(groups, num_channels)\n",
    "    return nn.GroupNorm(g, num_channels)\n",
    "\n",
    "def act_fn(name=\"silu\"):\n",
    "    return nn.SiLU() if name == \"silu\" else nn.ReLU(inplace=True)\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, norm=\"group\", act=\"silu\"):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            gn(out_ch) if norm == \"group\" else nn.BatchNorm2d(out_ch),\n",
    "            act_fn(act),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            gn(out_ch) if norm == \"group\" else nn.BatchNorm2d(out_ch),\n",
    "            act_fn(act)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNetS_Physics_v2(nn.Module):\n",
    "    \"\"\"Physics-Head U-Net v2 (5-level)\"\"\"\n",
    "    def __init__(self, t_min=0.02, zw_dim=32):\n",
    "        super().__init__()\n",
    "        chs = [32, 64, 128, 256]\n",
    "        self.t_min = t_min\n",
    "        self.zw_dim = zw_dim\n",
    "        \n",
    "        self.e1 = ConvBlock(3, chs[0])\n",
    "        self.p1 = nn.MaxPool2d(2)\n",
    "        self.e2 = ConvBlock(chs[0], chs[1])\n",
    "        self.p2 = nn.MaxPool2d(2)\n",
    "        self.e3 = ConvBlock(chs[1], chs[2])\n",
    "        self.p3 = nn.MaxPool2d(2)\n",
    "        self.e4 = ConvBlock(chs[2], chs[3])\n",
    "        \n",
    "        self.t_head = nn.Sequential(\n",
    "            nn.Conv2d(chs[3], 64, 3, padding=1),\n",
    "            act_fn(\"silu\"),\n",
    "            nn.Conv2d(64, 3, 1)\n",
    "        )\n",
    "        \n",
    "        self.A_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.A_mlp = nn.Sequential(\n",
    "            nn.Conv2d(chs[3], 128, 1),\n",
    "            act_fn(\"silu\"),\n",
    "            nn.Conv2d(128, 3, 1)\n",
    "        )\n",
    "        \n",
    "        self.zw_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.zw_mlp = nn.Sequential(\n",
    "            nn.Linear(chs[3], 256),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(256, self.zw_dim)\n",
    "        )\n",
    "        \n",
    "        self.sigma_head = nn.Sequential(\n",
    "            nn.Conv2d(chs[3], 16, 3, padding=1),\n",
    "            act_fn(\"silu\"),\n",
    "            nn.Conv2d(16, 1, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, I_cam_lin):\n",
    "        x1 = self.e1(I_cam_lin)\n",
    "        x2 = self.e2(self.p1(x1))\n",
    "        x3 = self.e3(self.p2(x2))\n",
    "        x4 = self.e4(self.p3(x3))\n",
    "        \n",
    "        t_logits = self.t_head(x4)\n",
    "        t = torch.sigmoid(t_logits) * (1 - 2*self.t_min) + self.t_min\n",
    "        \n",
    "        A = self.A_mlp(self.A_pool(x4))\n",
    "        zw = self.zw_mlp(self.zw_pool(x4).flatten(1))\n",
    "        sigma2 = F.softplus(self.sigma_head(x4))\n",
    "        \n",
    "        return {\"t\": t, \"A\": A, \"zw\": zw, \"sigma2\": sigma2}\n",
    "\n",
    "class TRIDENT_v2(nn.Module):\n",
    "    def __init__(self, t_min=0.02):\n",
    "        super().__init__()\n",
    "        self.gamma = 2.2\n",
    "        self.t_min = t_min\n",
    "        self.phys = UNetS_Physics_v2(t_min=t_min)\n",
    "    \n",
    "    def forward(self, I_cam_l):\n",
    "        ph = self.phys(I_cam_l)\n",
    "        t, A = ph[\"t\"], ph[\"A\"]\n",
    "        \n",
    "        H, W = I_cam_l.shape[-2], I_cam_l.shape[-1]\n",
    "        t = F.interpolate(t, size=(H, W), mode=\"bilinear\", align_corners=False)\n",
    "        A_b = A.expand(-1, -1, H, W)\n",
    "        \n",
    "        numerator = I_cam_l - A_b * (1 - t)\n",
    "        denominator = torch.maximum(t, torch.tensor(self.t_min, device=t.device))\n",
    "        I_hat_l = clamp01(numerator / denominator)\n",
    "        \n",
    "        return I_hat_l\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class UNetS_Physics_v3(nn.Module):\n",
    "    \"\"\"Physics-Head U-Net v3 (6-level with CBAM)\"\"\"\n",
    "    def __init__(self, t_min=0.02, zw_dim=32):\n",
    "        super().__init__()\n",
    "        chs = [32, 64, 128, 256, 512]\n",
    "        self.t_min = t_min\n",
    "        self.zw_dim = zw_dim\n",
    "        \n",
    "        self.e1 = nn.Sequential(ConvBlock(3, chs[0]), CBAM(chs[0]))\n",
    "        self.p1 = nn.MaxPool2d(2)\n",
    "        self.e2 = nn.Sequential(ConvBlock(chs[0], chs[1]), CBAM(chs[1]))\n",
    "        self.p2 = nn.MaxPool2d(2)\n",
    "        self.e3 = nn.Sequential(ConvBlock(chs[1], chs[2]), CBAM(chs[2]))\n",
    "        self.p3 = nn.MaxPool2d(2)\n",
    "        self.e4 = nn.Sequential(ConvBlock(chs[2], chs[3]), CBAM(chs[3]))\n",
    "        self.p4 = nn.MaxPool2d(2)\n",
    "        self.e5 = nn.Sequential(ConvBlock(chs[3], chs[4]), CBAM(chs[4]))\n",
    "        \n",
    "        self.t_head = nn.Sequential(\n",
    "            nn.Conv2d(chs[4], 64, 3, padding=1),\n",
    "            act_fn(\"silu\"),\n",
    "            nn.Conv2d(64, 3, 1)\n",
    "        )\n",
    "        \n",
    "        self.A_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.A_mlp = nn.Sequential(\n",
    "            nn.Conv2d(chs[4], 128, 1),\n",
    "            act_fn(\"silu\"),\n",
    "            nn.Conv2d(128, 3, 1)\n",
    "        )\n",
    "        \n",
    "        self.zw_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.zw_mlp = nn.Sequential(\n",
    "            nn.Linear(chs[4], 256),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(256, self.zw_dim)\n",
    "        )\n",
    "        \n",
    "        self.sigma_head = nn.Sequential(\n",
    "            nn.Conv2d(chs[4], 16, 3, padding=1),\n",
    "            act_fn(\"silu\"),\n",
    "            nn.Conv2d(16, 1, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, I_cam_lin):\n",
    "        x1 = self.e1(I_cam_lin)\n",
    "        x2 = self.e2(self.p1(x1))\n",
    "        x3 = self.e3(self.p2(x2))\n",
    "        x4 = self.e4(self.p3(x3))\n",
    "        x5 = self.e5(self.p4(x4))\n",
    "        \n",
    "        t_logits = self.t_head(x5)\n",
    "        t = torch.sigmoid(t_logits) * (1 - 2*self.t_min) + self.t_min\n",
    "        \n",
    "        A = self.A_mlp(self.A_pool(x5))\n",
    "        zw = self.zw_mlp(self.zw_pool(x5).flatten(1))\n",
    "        sigma2 = F.softplus(self.sigma_head(x5))\n",
    "        \n",
    "        return {\"t\": t, \"A\": A, \"zw\": zw, \"sigma2\": sigma2}\n",
    "\n",
    "class TRIDENT_v3(nn.Module):\n",
    "    def __init__(self, t_min=0.02):\n",
    "        super().__init__()\n",
    "        self.gamma = 2.2\n",
    "        self.t_min = t_min\n",
    "        self.phys = UNetS_Physics_v3(t_min=t_min)\n",
    "        \n",
    "        self.zw_to_t_bias = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(64, 3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, I_cam_l):\n",
    "        ph = self.phys(I_cam_l)\n",
    "        t, A, zw = ph[\"t\"], ph[\"A\"], ph[\"zw\"]\n",
    "        \n",
    "        t_bias = self.zw_to_t_bias(zw).unsqueeze(-1).unsqueeze(-1)\n",
    "        t_bias = torch.clamp(t_bias, -0.02, 0.02)\n",
    "        t = torch.clamp(t + t_bias, min=self.t_min, max=1.0)\n",
    "        \n",
    "        H, W = I_cam_l.shape[-2], I_cam_l.shape[-1]\n",
    "        t = F.interpolate(t, size=(H, W), mode=\"bilinear\", align_corners=False)\n",
    "        A_b = A.expand(-1, -1, H, W)\n",
    "        A_b = torch.clamp(A_b, 0.0, 1.0)\n",
    "        \n",
    "        numerator = torch.clamp(I_cam_l - A_b * (1 - t), min=1e-8)\n",
    "        denominator = torch.clamp(t, min=1e-8)\n",
    "        ratio = numerator / denominator\n",
    "        I_hat_l = torch.clamp(ratio, 0.0, 5.0)\n",
    "        I_hat_l = torch.clamp(I_hat_l, 0.0, 1.0)\n",
    "        \n",
    "        return I_hat_l\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD ALL MODELS\n",
    "# ============================================================================\n",
    "\n",
    "def load_all_models(device):\n",
    "    \"\"\"Load all 4 models\"\"\"\n",
    "    models = {}\n",
    "    \n",
    "    # 1. Attention Model\n",
    "    print(\"Loading Attention model...\")\n",
    "    attention_model = ResNet34_UNet_CBAM().to(device)\n",
    "    attention_ckpt = torch.load(CFG[\"checkpoints\"][\"attention\"], map_location=device)\n",
    "    attention_model.load_state_dict(attention_ckpt)\n",
    "    attention_model.eval()\n",
    "    models[\"attention\"] = attention_model\n",
    "    \n",
    "    # 2. Physics v2\n",
    "    print(\"Loading Physics v2 model...\")\n",
    "    phy_v2_model = TRIDENT_v2().to(device)\n",
    "    phy_v2_ckpt = torch.load(CFG[\"checkpoints\"][\"phy_v2\"], map_location=device)\n",
    "    phy_v2_model.load_state_dict(phy_v2_ckpt)\n",
    "    phy_v2_model.eval()\n",
    "    models[\"phy_v2\"] = phy_v2_model\n",
    "    \n",
    "    # 3. Physics v3\n",
    "    print(\"Loading Physics v3 model...\")\n",
    "    phy_v3_model = TRIDENT_v3().to(device)\n",
    "    phy_v3_ckpt = torch.load(CFG[\"checkpoints\"][\"phy_v3\"], map_location=device)\n",
    "    phy_v3_model.load_state_dict(phy_v3_ckpt)\n",
    "    phy_v3_model.eval()\n",
    "    models[\"phy_v3\"] = phy_v3_model\n",
    "    \n",
    "    print(\"✓ All models loaded successfully\")\n",
    "    return models\n",
    "\n",
    "# ============================================================================\n",
    "# METRICS CALCULATION (FOR METHODS WITHOUT PHY_V3)\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_metrics_batch1(dataset, models, device):\n",
    "    \"\"\"Calculate metrics for: attention, classical, phy_v2, attention+post\"\"\"\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=CFG[\"batch_size\"], \n",
    "                          shuffle=False, num_workers=0, pin_memory=True)\n",
    "    \n",
    "    results = {\n",
    "        \"attention\": {\"ssim\": [], \"psnr\": []},\n",
    "        \"classical\": {\"ssim\": [], \"psnr\": []},\n",
    "        \"phy_v2\": {\"ssim\": [], \"psnr\": []},\n",
    "        \"attention_post\": {\"ssim\": [], \"psnr\": []}\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CALCULATING METRICS - BATCH 1\")\n",
    "    print(\"Methods: attention, classical_physics, phy_v2, attention+post\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Processing Batch 1\"):\n",
    "            I_cam_srgb = batch[\"I_cam_srgb\"].to(device)\n",
    "            I_cam_lin = batch[\"I_cam_lin\"].to(device)\n",
    "            I_ref_srgb = batch[\"I_clean_srgb\"].to(device)\n",
    "            I_ref_lin = batch[\"I_clean_lin\"].to(device)\n",
    "            filenames = batch[\"filename\"]\n",
    "            \n",
    "            # 1. Attention Model\n",
    "            pred_attention = models[\"attention\"](I_cam_srgb)\n",
    "            \n",
    "            for i in range(pred_attention.shape[0]):\n",
    "                ssim = calculate_ssim(pred_attention[i:i+1], I_ref_srgb[i:i+1])\n",
    "                psnr = calculate_psnr(pred_attention[i:i+1], I_ref_srgb[i:i+1])\n",
    "                results[\"attention\"][\"ssim\"].append(ssim)\n",
    "                results[\"attention\"][\"psnr\"].append(psnr)\n",
    "            \n",
    "            # 2. Classical Physics (compute on the fly)\n",
    "            pred_classical_srgb = compute_classical(I_cam_srgb)\n",
    "\n",
    "            for i in range(pred_classical_srgb.shape[0]):\n",
    "                ssim = calculate_ssim(pred_classical_srgb[i:i+1], I_ref_srgb[i:i+1])\n",
    "                psnr = calculate_psnr(pred_classical_srgb[i:i+1], I_ref_srgb[i:i+1])\n",
    "                results[\"classical\"][\"ssim\"].append(ssim)\n",
    "                results[\"classical\"][\"psnr\"].append(psnr)\n",
    "            # 3. Physics v2\n",
    "            pred_v2_lin = models[\"phy_v2\"](I_cam_lin)\n",
    "            pred_v2_srgb = to_srgb(pred_v2_lin, 2.2)\n",
    "            \n",
    "            for i in range(pred_v2_srgb.shape[0]):\n",
    "                ssim = calculate_ssim(pred_v2_srgb[i:i+1], I_ref_srgb[i:i+1])\n",
    "                psnr = calculate_psnr(pred_v2_srgb[i:i+1], I_ref_srgb[i:i+1])\n",
    "                results[\"phy_v2\"][\"ssim\"].append(ssim)\n",
    "                results[\"phy_v2\"][\"psnr\"].append(psnr)\n",
    "            \n",
    "            # 4. Attention + Post-processing\n",
    "            pred_attention_post = clahe_enhancement(pred_attention)\n",
    "            pred_attention_post = adaptive_red_boost(pred_attention_post)\n",
    "            \n",
    "            for i in range(pred_attention_post.shape[0]):\n",
    "                ssim = calculate_ssim(pred_attention_post[i:i+1], I_ref_srgb[i:i+1])\n",
    "                psnr = calculate_psnr(pred_attention_post[i:i+1], I_ref_srgb[i:i+1])\n",
    "                results[\"attention_post\"][\"ssim\"].append(ssim)\n",
    "                results[\"attention_post\"][\"psnr\"].append(psnr)\n",
    "    \n",
    "    # Calculate averages\n",
    "    summary = {}\n",
    "    for method, metrics in results.items():\n",
    "        summary[method] = {\n",
    "            \"avg_ssim\": np.mean(metrics[\"ssim\"]),\n",
    "            \"avg_psnr\": np.mean(metrics[\"psnr\"]),\n",
    "            \"std_ssim\": np.std(metrics[\"ssim\"]),\n",
    "            \"std_psnr\": np.std(metrics[\"psnr\"])\n",
    "        }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BATCH 1 RESULTS:\")\n",
    "    print(\"=\"*60)\n",
    "    for method, stats in summary.items():\n",
    "        print(f\"{method:20s} | SSIM: {stats['avg_ssim']:.4f} ± {stats['std_ssim']:.4f} | \"\n",
    "              f\"PSNR: {stats['avg_psnr']:.2f} ± {stats['std_psnr']:.2f} dB\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return results, summary\n",
    "\n",
    "print(\"✓ Part 2 loaded - Continue to Part 3 for remaining metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31689ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "UNDERWATER IMAGE DENOISING - MODEL COMPARISON\n",
      "======================================================================\n",
      "Using device: cuda\n",
      "\n",
      "Loading dataset...\n",
      "Found 21521 image pairs\n",
      "Full dataset size: 21521\n",
      "Using a random 15% sample: 3228 images\n",
      "Loading Attention model...\n",
      "Loading Physics v2 model...\n",
      "Loading Physics v3 model...\n",
      "✓ All models loaded successfully\n",
      "\n",
      "============================================================\n",
      "CALCULATING METRICS - BATCH 1\n",
      "Methods: attention, classical_physics, phy_v2, attention+post\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch 1: 100%|██████████| 202/202 [02:15<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BATCH 1 RESULTS:\n",
      "============================================================\n",
      "attention            | SSIM: 0.7406 ± 0.0880 | PSNR: 19.44 ± 2.88 dB\n",
      "classical            | SSIM: 0.7129 ± 0.1069 | PSNR: 14.95 ± 2.81 dB\n",
      "phy_v2               | SSIM: 0.8392 ± 0.0896 | PSNR: 22.03 ± 3.59 dB\n",
      "attention_post       | SSIM: 0.8272 ± 0.0894 | PSNR: 19.18 ± 3.38 dB\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "CALCULATING METRICS - BATCH 2\n",
      "Methods: phy_v3, phy_v3+post\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch 2: 100%|██████████| 202/202 [01:03<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BATCH 2 RESULTS:\n",
      "============================================================\n",
      "phy_v3               | SSIM: 0.8322 ± 0.0989 | PSNR: 19.23 ± 3.90 dB\n",
      "phy_v3_post          | SSIM: 0.7077 ± 0.1055 | PSNR: 15.37 ± 2.51 dB\n",
      "============================================================\n",
      "\n",
      "======================================================================\n",
      "FINAL SUMMARY - ALL METHODS\n",
      "======================================================================\n",
      "Attention                 | SSIM: 0.7406 ± 0.0880 | PSNR: 19.44 ± 2.88 dB\n",
      "Classical Physics         | SSIM: 0.7129 ± 0.1069 | PSNR: 14.95 ± 2.81 dB\n",
      "Physics v2                | SSIM: 0.8392 ± 0.0896 | PSNR: 22.03 ± 3.59 dB\n",
      "Physics v3                | SSIM: 0.8322 ± 0.0989 | PSNR: 19.23 ± 3.90 dB\n",
      "Attention + Post          | SSIM: 0.8272 ± 0.0894 | PSNR: 19.18 ± 3.38 dB\n",
      "Physics v3 + Post         | SSIM: 0.7077 ± 0.1055 | PSNR: 15.37 ± 2.51 dB\n",
      "======================================================================\n",
      "\n",
      "============================================================\n",
      "GENERATING COMPARISON IMAGES\n",
      "Total: 18 images × 8 columns\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating comparisons: 100%|██████████| 18/18 [00:12<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved 18 comparison images to: comparison_results\\comparison_images\n",
      "✓ Saved metrics to: comparison_results\\metrics_summary.json\n",
      "\n",
      "======================================================================\n",
      "✓ ALL DONE!\n",
      "Results saved to: comparison_results\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Part 3: Calculate v3 metrics and Generate comparison visualizations\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# ============================================================================\n",
    "# METRICS CALCULATION (FOR V3 METHODS)\n",
    "# ============================================================================\n",
    "\n",
    "# ============================================================================\n",
    "# METRICS CALCULATION (FOR V3 METHODS)\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_metrics_batch2(dataset, models, device):\n",
    "    \"\"\"Calculate metrics for: phy_v3, phy_v3+post\"\"\"\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=CFG[\"batch_size\"], \n",
    "                          shuffle=False, num_workers=0, pin_memory=True)\n",
    "    \n",
    "    results = {\n",
    "        \"phy_v3\": {\"ssim\": [], \"psnr\": []},\n",
    "        \"phy_v3_post\": {\"ssim\": [], \"psnr\": []}\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CALCULATING METRICS - BATCH 2\")\n",
    "    print(\"Methods: phy_v3, phy_v3+post\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Processing Batch 2\"):\n",
    "            I_cam_lin = batch[\"I_cam_lin\"].to(device)\n",
    "            I_ref_srgb = batch[\"I_clean_srgb\"].to(device)\n",
    "            \n",
    "            # 1. Physics v3\n",
    "            pred_v3_lin = models[\"phy_v3\"](I_cam_lin)\n",
    "            pred_v3_srgb = to_srgb(pred_v3_lin, 2.2)\n",
    "            \n",
    "            for i in range(pred_v3_srgb.shape[0]):\n",
    "                ssim = calculate_ssim(pred_v3_srgb[i:i+1], I_ref_srgb[i:i+1])\n",
    "                psnr = calculate_psnr(pred_v3_srgb[i:i+1], I_ref_srgb[i:i+1])\n",
    "                results[\"phy_v3\"][\"ssim\"].append(ssim)\n",
    "                results[\"phy_v3\"][\"psnr\"].append(psnr)\n",
    "            \n",
    "            # 2. Physics v3 + Post-processing\n",
    "            pred_v3_post = clahe_enhancement(pred_v3_srgb)\n",
    "            pred_v3_post = adaptive_red_boost(pred_v3_post)\n",
    "            \n",
    "            for i in range(pred_v3_post.shape[0]):\n",
    "                ssim = calculate_ssim(pred_v3_post[i:i+1], I_ref_srgb[i:i+1])\n",
    "                psnr = calculate_psnr(pred_v3_post[i:i+1], I_ref_srgb[i:i+1])\n",
    "                results[\"phy_v3_post\"][\"ssim\"].append(ssim)\n",
    "                results[\"phy_v3_post\"][\"psnr\"].append(psnr)\n",
    "    \n",
    "    # Calculate averages\n",
    "    summary = {}\n",
    "    for method, metrics in results.items():\n",
    "        summary[method] = {\n",
    "            \"avg_ssim\": np.mean(metrics[\"ssim\"]),\n",
    "            \"avg_psnr\": np.mean(metrics[\"psnr\"]),\n",
    "            \"std_ssim\": np.std(metrics[\"ssim\"]),\n",
    "            \"std_psnr\": np.std(metrics[\"psnr\"])\n",
    "        }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BATCH 2 RESULTS:\")\n",
    "    print(\"=\"*60)\n",
    "    for method, stats in summary.items():\n",
    "        print(f\"{method:20s} | SSIM: {stats['avg_ssim']:.4f} ± {stats['std_ssim']:.4f} | \"\n",
    "              f\"PSNR: {stats['avg_psnr']:.2f} ± {stats['std_psnr']:.2f} dB\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return results, summary\n",
    "\n",
    "# ============================================================================\n",
    "# IMAGE COMPARISON VISUALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "def generate_comparison_images(dataset, models, all_results, device):\n",
    "    \"\"\"Generate 18 comparison images (8 columns each)\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.gridspec import GridSpec\n",
    "    \n",
    "    # Merge all results\n",
    "    all_ssim = {}\n",
    "    for method in [\"attention\", \"classical\", \"phy_v2\", \"phy_v3\", \"attention_post\", \"phy_v3_post\"]:\n",
    "        if method in all_results:\n",
    "            all_ssim[method] = all_results[method][\"ssim\"]\n",
    "    \n",
    "    num_images = len(dataset)\n",
    "    \n",
    "    # 1. Select 6 random images\n",
    "    np.random.seed(42)\n",
    "    random_indices = np.random.choice(num_images, 6, replace=False)\n",
    "    \n",
    "    # 2. Select best image for each method (6 images)\n",
    "    best_indices = []\n",
    "    for method in [\"attention\", \"classical\", \"phy_v2\", \"phy_v3\", \"attention_post\", \"phy_v3_post\"]:\n",
    "        best_idx = np.argmax(all_ssim[method])\n",
    "        best_indices.append(best_idx)\n",
    "    \n",
    "    # 3. Select worst image for each method (6 images)\n",
    "    worst_indices = []\n",
    "    for method in [\"attention\", \"classical\", \"phy_v2\", \"phy_v3\", \"attention_post\", \"phy_v3_post\"]:\n",
    "        worst_idx = np.argmin(all_ssim[method])\n",
    "        worst_indices.append(worst_idx)\n",
    "    \n",
    "    # Combine all indices (18 total)\n",
    "    all_indices = list(random_indices) + best_indices + worst_indices\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"GENERATING COMPARISON IMAGES\")\n",
    "    print(f\"Total: 18 images × 8 columns\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "\n",
    "    output_dir = os.path.join(CFG[\"results_dir\"], \"comparison_images\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    method_names = [\"Attention\", \"Classical\", \"Phy-v2\", \"Phy-v3\", \"Att+Post\", \"V3+Post\"]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx_num, img_idx in enumerate(tqdm(all_indices, desc=\"Generating comparisons\")):\n",
    "            # Load data\n",
    "            data = dataset[img_idx]\n",
    "            I_cam_srgb = data[\"I_cam_srgb\"].unsqueeze(0).to(device)\n",
    "            I_cam_lin = data[\"I_cam_lin\"].unsqueeze(0).to(device)\n",
    "            I_ref_srgb = data[\"I_clean_srgb\"].unsqueeze(0).to(device)\n",
    "            filename = data[\"filename\"]\n",
    "            \n",
    "            # Generate predictions\n",
    "            predictions = {}\n",
    "            \n",
    "            # Attention\n",
    "            predictions[\"attention\"] = models[\"attention\"](I_cam_srgb)\n",
    "            \n",
    "            # Classical\n",
    "            predictions[\"classical\"] = compute_classical(I_cam_srgb)\n",
    "            \n",
    "            # Physics v2\n",
    "            pred_v2_lin = models[\"phy_v2\"](I_cam_lin)\n",
    "            predictions[\"phy_v2\"] = to_srgb(pred_v2_lin, 2.2)\n",
    "            \n",
    "            # Physics v3\n",
    "            pred_v3_lin = models[\"phy_v3\"](I_cam_lin)\n",
    "            predictions[\"phy_v3\"] = to_srgb(pred_v3_lin, 2.2)\n",
    "            \n",
    "            # Attention + Post\n",
    "            predictions[\"attention_post\"] = clahe_enhancement(predictions[\"attention\"])\n",
    "            predictions[\"attention_post\"] = adaptive_red_boost(predictions[\"attention_post\"])\n",
    "            \n",
    "            # Physics v3 + Post\n",
    "            predictions[\"phy_v3_post\"] = clahe_enhancement(predictions[\"phy_v3\"])\n",
    "            predictions[\"phy_v3_post\"] = adaptive_red_boost(predictions[\"phy_v3_post\"])\n",
    "            \n",
    "            # Calculate SSIM for each method\n",
    "            ssims = {}\n",
    "            psnrs = {}\n",
    "            for method_key, method_name in zip(\n",
    "                [\"attention\", \"classical\", \"phy_v2\", \"phy_v3\", \"attention_post\", \"phy_v3_post\"],\n",
    "                method_names\n",
    "            ):\n",
    "                ssims[method_name] = calculate_ssim(predictions[method_key], I_ref_srgb)\n",
    "                psnrs[method_name] = calculate_psnr(predictions[method_key], I_ref_srgb)\n",
    "            \n",
    "            # Create visualization\n",
    "            fig = plt.figure(figsize=(24, 4))\n",
    "            gs = GridSpec(1, 8, figure=fig, wspace=0.02, hspace=0)\n",
    "            \n",
    "            # Helper to convert tensor to numpy\n",
    "            def tensor_to_numpy(t):\n",
    "                return t.squeeze(0).cpu().permute(1, 2, 0).numpy()\n",
    "            \n",
    "            # Plot images\n",
    "            images = [\n",
    "                (\"Icam\", tensor_to_numpy(I_cam_srgb)),\n",
    "                (\"Attention\\nSSIM:{:.3f}\\nPSNR:{:.1f}\".format(ssims[\"Attention\"], psnrs[\"Attention\"]), \n",
    "                 tensor_to_numpy(predictions[\"attention\"])),\n",
    "                (\"Classical\\nSSIM:{:.3f}\\nPSNR:{:.1f}\".format(ssims[\"Classical\"], psnrs[\"Classical\"]), \n",
    "                 tensor_to_numpy(predictions[\"classical\"])),\n",
    "                (\"Phy-v2\\nSSIM:{:.3f}\\nPSNR:{:.1f}\".format(ssims[\"Phy-v2\"], psnrs[\"Phy-v2\"]), \n",
    "                 tensor_to_numpy(predictions[\"phy_v2\"])),\n",
    "                (\"Phy-v3\\nSSIM:{:.3f}\\nPSNR:{:.1f}\".format(ssims[\"Phy-v3\"], psnrs[\"Phy-v3\"]), \n",
    "                 tensor_to_numpy(predictions[\"phy_v3\"])),\n",
    "                (\"Att+Post\\nSSIM:{:.3f}\\nPSNR:{:.1f}\".format(ssims[\"Att+Post\"], psnrs[\"Att+Post\"]), \n",
    "                 tensor_to_numpy(predictions[\"attention_post\"])),\n",
    "                (\"V3+Post\\nSSIM:{:.3f}\\nPSNR:{:.1f}\".format(ssims[\"V3+Post\"], psnrs[\"V3+Post\"]), \n",
    "                 tensor_to_numpy(predictions[\"phy_v3_post\"])),\n",
    "                (\"Iclean\", tensor_to_numpy(I_ref_srgb))\n",
    "            ]\n",
    "            \n",
    "            for col_idx, (title, img) in enumerate(images):\n",
    "                ax = fig.add_subplot(gs[0, col_idx])\n",
    "                ax.imshow(img)\n",
    "                ax.set_title(title, fontsize=8)\n",
    "                ax.axis('off')\n",
    "            \n",
    "            # Determine category\n",
    "            if idx_num < 6:\n",
    "                category = \"random\"\n",
    "                save_filename = f\"comparison_{category}_{idx_num+1:02d}.png\"\n",
    "            elif idx_num < 12:\n",
    "                method_idx = idx_num - 6\n",
    "                category = f\"best_{method_names[method_idx]}\"\n",
    "                save_filename = f\"comparison_{category}.png\"\n",
    "            else:\n",
    "                method_idx = idx_num - 12\n",
    "                category = f\"worst_{method_names[method_idx]}\"\n",
    "                save_filename = f\"comparison_{category}.png\"\n",
    "            \n",
    "            save_path = os.path.join(output_dir, save_filename)\n",
    "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "            plt.close()\n",
    "    \n",
    "    print(f\"✓ Saved {len(all_indices)} comparison images to: {output_dir}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE RESULTS TO JSON\n",
    "# ============================================================================\n",
    "\n",
    "def save_results_to_json(all_summaries, all_results):\n",
    "    \"\"\"Save all metrics to JSON file\"\"\"\n",
    "    output = {\n",
    "        \"summary\": all_summaries,\n",
    "        \"detailed_results\": {\n",
    "            method: {\n",
    "                \"ssim\": [float(x) for x in metrics[\"ssim\"]],\n",
    "                \"psnr\": [float(x) for x in metrics[\"psnr\"]]\n",
    "            }\n",
    "            for method, metrics in all_results.items()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    output_path = os.path.join(CFG[\"results_dir\"], \"metrics_summary.json\")\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(output, f, indent=2)\n",
    "    \n",
    "    print(f\"✓ Saved metrics to: {output_path}\")\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"UNDERWATER IMAGE DENOISING - MODEL COMPARISON\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    device = torch.device(CFG[\"device\"])\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load dataset\n",
    "    print(\"\\nLoading dataset...\")\n",
    "    full_dataset = FullDataset(\n",
    "        CFG[\"data\"][\"root_cam\"],\n",
    "        CFG[\"data\"][\"root_ref\"],\n",
    "        CFG[\"data\"][\"img_size\"]\n",
    "    )\n",
    "\n",
    "    # --- NEW: Randomly sample 15% of the dataset ---\n",
    "    print(f\"Full dataset size: {len(full_dataset)}\")\n",
    "    num_total = len(full_dataset)\n",
    "    num_sample = int(num_total * 0.15)\n",
    "\n",
    "    # Ensure we have at least 1 image to sample\n",
    "    if num_sample == 0 and num_total > 0:\n",
    "        num_sample = 1\n",
    "\n",
    "    np.random.seed(42) # for reproducible sampling\n",
    "    all_indices = list(range(num_total))\n",
    "    np.random.shuffle(all_indices)\n",
    "    sample_indices = all_indices[:num_sample]\n",
    "\n",
    "    sample_dataset = torch.utils.data.Subset(full_dataset, sample_indices)\n",
    "    print(f\"Using a random 15% sample: {len(sample_dataset)} images\")\n",
    "    # --- END NEW ---\n",
    "\n",
    "    # Load models\n",
    "    models = load_all_models(device)\n",
    "\n",
    "    # Calculate metrics - Batch 1 (using sample_dataset)\n",
    "    results_batch1, summary_batch1 = calculate_metrics_batch1(sample_dataset, models, device)\n",
    "\n",
    "    # Calculate metrics - Batch 2 (using sample_dataset)\n",
    "    results_batch2, summary_batch2 = calculate_metrics_batch2(sample_dataset, models, device)\n",
    "    \n",
    "    # Merge results\n",
    "    all_results = {**results_batch1, **results_batch2}\n",
    "    all_summaries = {**summary_batch1, **summary_batch2}\n",
    "    \n",
    "    # Print final summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FINAL SUMMARY - ALL METHODS\")\n",
    "    print(\"=\"*70)\n",
    "    method_order = [\"attention\", \"classical\", \"phy_v2\", \"phy_v3\", \"attention_post\", \"phy_v3_post\"]\n",
    "    method_display = [\"Attention\", \"Classical Physics\", \"Physics v2\", \"Physics v3\", \n",
    "                     \"Attention + Post\", \"Physics v3 + Post\"]\n",
    "    \n",
    "    for method, display_name in zip(method_order, method_display):\n",
    "        stats = all_summaries[method]\n",
    "        print(f\"{display_name:25s} | SSIM: {stats['avg_ssim']:.4f} ± {stats['std_ssim']:.4f} | \"\n",
    "              f\"PSNR: {stats['avg_psnr']:.2f} ± {stats['std_psnr']:.2f} dB\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Generate comparison images\n",
    "    generate_comparison_images(sample_dataset, models, all_results, device)\n",
    "    \n",
    "    # Save results\n",
    "    save_results_to_json(all_summaries, all_results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"✓ ALL DONE!\")\n",
    "    print(f\"Results saved to: {CFG['results_dir']}\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf0a760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcb3c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9275e438",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
