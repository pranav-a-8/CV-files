{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TRIDENT Physics-Only Model - Underwater Image Restoration\n",
    "Simplified version using only the Physics-Head U-Net\n",
    "\"\"\"\n",
    "\n",
    "import os, math, random, time, json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, Any, Tuple\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION (consolidated from YAML)\n",
    "# ============================================================================\n",
    "\n",
    "CFG = {\n",
    "    \"seed\": 42,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"amp\": True,\n",
    "    \n",
    "    \"ema\": {\n",
    "        \"enabled\": True,\n",
    "        \"decay\": 0.9995\n",
    "    },\n",
    "    \n",
    "    \"data\": {\n",
    "        \"root_cam\": \"D:/ML_works/TRIDENT/DATA/Icam\",\n",
    "        \"root_ref\": \"D:/ML_works/TRIDENT/DATA/Iclean\",\n",
    "        \"img_size\": 256,\n",
    "        \"filename_pattern\": \"{:d}.png\",\n",
    "        \"index_start\": 1,\n",
    "        \"count\": 21521,\n",
    "        \"splits\": {\n",
    "            \"train\": 18000,\n",
    "            \"val\": 1760,\n",
    "            \"test\": 1761\n",
    "        },\n",
    "        \"loader\": {\n",
    "            \"batch_size\": 32,# Increased from 24 (more memory available)\n",
    "            \"num_workers\": 0,\n",
    "            \"pin_memory\": True\n",
    "        },\n",
    "        \"aug\": {\n",
    "            \"hflip_p\": 0.5,\n",
    "            \"rotate_deg\": 10,\n",
    "            \"paired_crop_240\": True,\n",
    "            \"jitter_cam\": {\n",
    "                \"brightness\": 0.1,\n",
    "                \"contrast\": 0.1,\n",
    "                \"prob\": 0.3\n",
    "            },\n",
    "            \"gamma_train_choices\": [0.9, 1.0, 1.1],\n",
    "            \"gamma_train_probs\": [0.25, 0.50, 0.25],\n",
    "            \"gamma_eval\": 1.0\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"model\": {\n",
    "        \"colorspace\": {\n",
    "            \"gamma\": 2.2\n",
    "        },\n",
    "        \"physics\": {\n",
    "            \"unet_channels\": [32, 64, 128, 256],\n",
    "            \"norm\": \"group\",\n",
    "            \"act\": \"silu\",\n",
    "            \"t_min\": 0.02,\n",
    "            \"z_w_dim\": 32\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"loss\": {\n",
    "        \"weights\": {\n",
    "            \"phys\": 0.1,       # Reduced: now just regularization\n",
    "            \"tv_t\": 5.0e-4,    # Keep same\n",
    "            \"A_prior\": 5.0e-3, # Keep same\n",
    "            \"hetero\": 0.2      # Keep same\n",
    "        },\n",
    "        \"heteroscedastic\": {\n",
    "            \"epsilon\": 1.0e-6,\n",
    "            \"start_epoch\": 12,\n",
    "            \"watchdog\": {\n",
    "                \"mean_sigma2_thresh\": 0.5,\n",
    "                \"over_thresh_required\": 2,\n",
    "                \"cooldown_epochs\": 2\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"schedules\": {\n",
    "        \"epochs\": 30,\n",
    "        \"warmup_steps\": 3000,\n",
    "        \"lr\": {\n",
    "            \"base\": 3.5e-4,\n",
    "            \"min\": 1.0e-8,\n",
    "            \"decay\": \"cosine\"\n",
    "        },\n",
    "        \"hetero\": {\n",
    "            \"start_epoch\": 8,\n",
    "            \"weight\": 0.2\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"optimizer\": {\n",
    "        \"name\": \"adamw\",\n",
    "        \"betas\": [0.9, 0.99],\n",
    "        \"weight_decay\": 1.0e-4,\n",
    "        \"grad_clip\": 0.5\n",
    "    },\n",
    "    \n",
    "    \"logging\": {\n",
    "        \"save_best\": {\n",
    "            \"by_primary\": True,\n",
    "            \"by_secondary\": True\n",
    "        },\n",
    "        \"export_test\": {\n",
    "            \"tAzw\": True,\n",
    "            \"save_images\": True,\n",
    "            \"dir\": \"outputs/test_exports\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Set seed for reproducibility\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(CFG[\"seed\"])\n",
    "DEVICE = CFG[\"device\"]\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# ============================================================================\n",
    "# COLOR SPACE UTILITIES\n",
    "# ============================================================================\n",
    "\n",
    "def to_linear(img_srgb: torch.Tensor, gamma: float = 2.2) -> torch.Tensor:\n",
    "    \"\"\"Convert sRGB to linear RGB\"\"\"\n",
    "    return torch.clamp(img_srgb, 0.0, 1.0).pow(gamma)\n",
    "\n",
    "def to_srgb(img_lin: torch.Tensor, gamma: float = 2.2) -> torch.Tensor:\n",
    "    \"\"\"Convert linear RGB to sRGB\"\"\"\n",
    "    return torch.clamp(img_lin, 0.0, 1.0).pow(1.0 / gamma)\n",
    "\n",
    "def clamp01(x: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.clamp(x, 0.0, 1.0)\n",
    "\n",
    "# ============================================================================\n",
    "# NEURAL NETWORK UTILITIES\n",
    "# ============================================================================\n",
    "\n",
    "def gn(num_channels, groups=8):\n",
    "    \"\"\"Group normalization helper\"\"\"\n",
    "    g = min(groups, num_channels)\n",
    "    return nn.GroupNorm(g, num_channels)\n",
    "\n",
    "def act_fn(name=\"silu\"):\n",
    "    \"\"\"Activation function helper\"\"\"\n",
    "    return nn.SiLU() if name == \"silu\" else nn.ReLU(inplace=True)\n",
    "\n",
    "# ============================================================================\n",
    "# DATASET\n",
    "# ============================================================================\n",
    "\n",
    "class PairedDataset(Dataset):\n",
    "    def __init__(self, split, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.gamma = cfg[\"model\"][\"colorspace\"][\"gamma\"]\n",
    "        self.split = split\n",
    "        self.train = split == \"train\"\n",
    "        self.size = cfg[\"data\"][\"img_size\"]\n",
    "        self.aug_cfg = cfg[\"data\"][\"aug\"]\n",
    "        \n",
    "        # Roots & filename pattern\n",
    "        self.root_cam = cfg[\"data\"][\"root_cam\"]\n",
    "        self.root_ref = cfg[\"data\"][\"root_ref\"]\n",
    "        pat = cfg[\"data\"][\"filename_pattern\"]\n",
    "        start = int(cfg[\"data\"][\"index_start\"])\n",
    "        total = int(cfg[\"data\"][\"count\"])\n",
    "        \n",
    "        # Deterministic ID list\n",
    "        ids = list(range(start, start + total))\n",
    "        \n",
    "        # Fixed split counts\n",
    "        n_train = int(cfg[\"data\"][\"splits\"][\"train\"])\n",
    "        n_val = int(cfg[\"data\"][\"splits\"][\"val\"])\n",
    "        n_test = int(cfg[\"data\"][\"splits\"][\"test\"])\n",
    "        assert n_train + n_val + n_test == total, \"splits must sum to data.count\"\n",
    "        \n",
    "        # Deterministic shuffle with seed\n",
    "        rng = random.Random(cfg[\"seed\"])\n",
    "        rng.shuffle(ids)\n",
    "        \n",
    "        if split == \"train\":\n",
    "            self.ids = ids[:n_train]\n",
    "        elif split == \"val\":\n",
    "            self.ids = ids[n_train:n_train+n_val]\n",
    "        else:\n",
    "            self.ids = ids[n_train+n_val:]\n",
    "        \n",
    "        # Verify existence\n",
    "        keep = []\n",
    "        for i in self.ids:\n",
    "            fname = pat.format(i)\n",
    "            p_cam = os.path.join(self.root_cam, fname)\n",
    "            p_ref = os.path.join(self.root_ref, fname)\n",
    "            if os.path.exists(p_cam) and os.path.exists(p_ref):\n",
    "                keep.append((p_cam, p_ref))\n",
    "        \n",
    "        missing = len(self.ids) - len(keep)\n",
    "        if missing > 0:\n",
    "            print(f\"[{split}] Warning: {missing} pairs missing; using {len(keep)}.\")\n",
    "        self.entries = keep\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.entries)\n",
    "    \n",
    "    def gamma_corr(self, img, gamma=1.0):\n",
    "        return clamp01(img ** gamma)\n",
    "    \n",
    "    def paired_augs(self, cam, ref):\n",
    "        \"\"\"Apply paired augmentations\"\"\"\n",
    "        HFLIP = self.aug_cfg.get(\"hflip_p\", 0.5)\n",
    "        ROT = int(self.aug_cfg.get(\"rotate_deg\", 10))\n",
    "        \n",
    "        if self.train and random.random() < HFLIP:\n",
    "            cam = ImageOps.mirror(cam)\n",
    "            ref = ImageOps.mirror(ref)\n",
    "        \n",
    "        if self.train and ROT > 0:\n",
    "            deg = random.uniform(-ROT, ROT)\n",
    "            cam = cam.rotate(deg, resample=Image.BILINEAR, fillcolor=None)\n",
    "            ref = ref.rotate(deg, resample=Image.BILINEAR, fillcolor=None)\n",
    "        \n",
    "        if self.train and self.aug_cfg.get(\"paired_crop_240\", True):\n",
    "            w, h = cam.size\n",
    "            if w >= 256 and h >= 256:\n",
    "                nw = nh = 240\n",
    "                x = random.randint(0, w - nw)\n",
    "                y = random.randint(0, h - nh)\n",
    "                cam = cam.crop((x, y, x+nw, y+nh)).resize((self.size, self.size), Image.BILINEAR)\n",
    "                ref = ref.crop((x, y, x+nw, y+nh)).resize((self.size, self.size), Image.BILINEAR)\n",
    "        else:\n",
    "            cam = cam.resize((self.size, self.size), Image.BILINEAR)\n",
    "            ref = ref.resize((self.size, self.size), Image.BILINEAR)\n",
    "        \n",
    "        return cam, ref\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        from torchvision import transforms\n",
    "        \n",
    "        p_cam, p_ref = self.entries[idx]\n",
    "        cam = Image.open(p_cam).convert(\"RGB\")\n",
    "        ref = Image.open(p_ref).convert(\"RGB\")\n",
    "        cam, ref = self.paired_augs(cam, ref)\n",
    "        \n",
    "        to_t = transforms.ToTensor()\n",
    "        cam_s = to_t(cam)\n",
    "        ref_s = to_t(ref)\n",
    "        \n",
    "        # Gamma augmentation\n",
    "        if self.train:\n",
    "            choices = self.aug_cfg[\"gamma_train_choices\"]\n",
    "            probs = self.aug_cfg[\"gamma_train_probs\"]\n",
    "            g = random.choices(choices, probs)[0]\n",
    "            if abs(g - 1.0) > 1e-6:\n",
    "                cam_s = self.gamma_corr(cam_s, g)\n",
    "        else:\n",
    "            cam_s = self.gamma_corr(cam_s, self.aug_cfg.get(\"gamma_eval\", 1.0))\n",
    "        \n",
    "        # Color jitter\n",
    "        if self.train and random.random() < self.aug_cfg[\"jitter_cam\"][\"prob\"]:\n",
    "            b = self.aug_cfg[\"jitter_cam\"][\"brightness\"]\n",
    "            c = self.aug_cfg[\"jitter_cam\"][\"contrast\"]\n",
    "            cam_s = transforms.ColorJitter(brightness=b, contrast=c)(cam_s)\n",
    "        \n",
    "        # Convert to linear\n",
    "        cam_l = to_linear(cam_s, self.gamma)\n",
    "        ref_l = to_linear(ref_s, self.gamma)\n",
    "        \n",
    "        return {\n",
    "            \"I_cam_srgb\": cam_s,\n",
    "            \"I_cam_lin\": cam_l,\n",
    "            \"I_clean_lin\": ref_l,\n",
    "            \"cam_path\": p_cam,\n",
    "            \"ref_path\": p_ref\n",
    "        }\n",
    "\n",
    "def get_loaders(cfg):\n",
    "    \"\"\"Create train/val/test data loaders\"\"\"\n",
    "    ds_train = PairedDataset(\"train\", cfg)\n",
    "    ds_val = PairedDataset(\"val\", cfg)\n",
    "    ds_test = PairedDataset(\"test\", cfg)\n",
    "    \n",
    "    bs = cfg[\"data\"][\"loader\"][\"batch_size\"]\n",
    "    nw = cfg[\"data\"][\"loader\"][\"num_workers\"]\n",
    "    pin = cfg[\"data\"][\"loader\"][\"pin_memory\"]\n",
    "    \n",
    "    dl_train = DataLoader(ds_train, batch_size=bs, shuffle=True, num_workers=nw, pin_memory=pin, drop_last=True)\n",
    "    dl_val = DataLoader(ds_val, batch_size=bs, shuffle=False, num_workers=nw, pin_memory=pin)\n",
    "    dl_test = DataLoader(ds_test, batch_size=bs, shuffle=False, num_workers=nw, pin_memory=pin)\n",
    "    \n",
    "    return dl_train, dl_val, dl_test\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL COMPONENTS\n",
    "# ============================================================================\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"Double convolution block with normalization and activation\"\"\"\n",
    "    def __init__(self, in_ch, out_ch, norm=\"group\", act=\"silu\"):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            gn(out_ch) if norm == \"group\" else nn.BatchNorm2d(out_ch),\n",
    "            act_fn(act),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            gn(out_ch) if norm == \"group\" else nn.BatchNorm2d(out_ch),\n",
    "            act_fn(act)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNetS_Physics(nn.Module):\n",
    "    \"\"\"Physics-Head U-Net for predicting t, A, z_w\"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        chs = cfg[\"model\"][\"physics\"][\"unet_channels\"]  # [32, 64, 128, 256]\n",
    "        norm = cfg[\"model\"][\"physics\"][\"norm\"]\n",
    "        act = cfg[\"model\"][\"physics\"][\"act\"]\n",
    "        self.t_min = cfg[\"model\"][\"physics\"][\"t_min\"]\n",
    "        self.zw_dim = cfg[\"model\"][\"physics\"][\"z_w_dim\"]\n",
    "        \n",
    "        # Encoder\n",
    "        self.e1 = ConvBlock(3, chs[0], norm, act)\n",
    "        self.p1 = nn.MaxPool2d(2)\n",
    "        self.e2 = ConvBlock(chs[0], chs[1], norm, act)\n",
    "        self.p2 = nn.MaxPool2d(2)\n",
    "        self.e3 = ConvBlock(chs[1], chs[2], norm, act)\n",
    "        self.p3 = nn.MaxPool2d(2)\n",
    "        self.e4 = ConvBlock(chs[2], chs[3], norm, act)\n",
    "        \n",
    "        # Transmission map head\n",
    "        self.t_head = nn.Sequential(\n",
    "            nn.Conv2d(chs[3], 64, 3, padding=1),\n",
    "            act_fn(act),\n",
    "            nn.Conv2d(64, 3, 1)\n",
    "        )\n",
    "        \n",
    "        # Atmospheric light head\n",
    "        self.A_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.A_mlp = nn.Sequential(\n",
    "            nn.Conv2d(chs[3], 128, 1),\n",
    "            act_fn(act),\n",
    "            nn.Conv2d(128, 3, 1)\n",
    "        )\n",
    "        \n",
    "        # Water properties embedding\n",
    "        self.zw_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.zw_mlp = nn.Sequential(\n",
    "            nn.Linear(chs[3], 256),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(256, self.zw_dim)\n",
    "        )\n",
    "        \n",
    "        # Heteroscedastic uncertainty head\n",
    "        self.sigma_head = nn.Sequential(\n",
    "            nn.Conv2d(chs[3], 16, 3, padding=1),\n",
    "            act_fn(act),\n",
    "            nn.Conv2d(16, 1, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, I_cam_lin):\n",
    "        # Encode\n",
    "        x1 = self.e1(I_cam_lin)      # 32, H/2\n",
    "        x2 = self.e2(self.p1(x1))    # 64, H/4\n",
    "        x3 = self.e3(self.p2(x2))    # 128, H/8\n",
    "        x4 = self.e4(self.p3(x3))    # 256, H/16 (bottleneck)\n",
    "        \n",
    "        # Transmission map (range: [t_min, 1])\n",
    "        t_logits = self.t_head(x4)\n",
    "        t = torch.sigmoid(t_logits) * (1 - 2*self.t_min) + self.t_min\n",
    "        \n",
    "        # Atmospheric light (global, RGB)\n",
    "        A = self.A_mlp(self.A_pool(x4))  # (B, 3, 1, 1)\n",
    "        \n",
    "        # Water properties embedding\n",
    "        zw = self.zw_mlp(self.zw_pool(x4).flatten(1))  # (B, zw_dim)\n",
    "        \n",
    "        # Heteroscedastic uncertainty\n",
    "        sigma2 = F.softplus(self.sigma_head(x4))  # (B, 1, H/16, W/16)\n",
    "        \n",
    "        return {\n",
    "            \"t\": t,\n",
    "            \"A\": A,\n",
    "            \"zw\": zw,\n",
    "            \"sigma2\": sigma2\n",
    "        }\n",
    "\n",
    "class TRIDENT(nn.Module):\n",
    "    \"\"\"Simplified TRIDENT - Physics-Head Only (CORRECTED - No Data Leak)\"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.gamma = cfg[\"model\"][\"colorspace\"][\"gamma\"]\n",
    "        self.t_min = cfg[\"model\"][\"physics\"][\"t_min\"]  # Add this line\n",
    "        self.phys = UNetS_Physics(cfg)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        I_cam_l = batch[\"I_cam_lin\"].to(DEVICE)\n",
    "        \n",
    "        # Physics head forward (only uses I_cam)\n",
    "        ph = self.phys(I_cam_l)\n",
    "        t, A, zw, sigma2 = ph[\"t\"], ph[\"A\"], ph[\"zw\"], ph[\"sigma2\"]\n",
    "        \n",
    "        # Upsample to full resolution\n",
    "        H, W = I_cam_l.shape[-2], I_cam_l.shape[-1]\n",
    "        t = F.interpolate(t, size=(H, W), mode=\"bilinear\", align_corners=False)\n",
    "        sigma2 = F.interpolate(sigma2, size=(H, W), mode=\"bilinear\", align_corners=False)\n",
    "        \n",
    "        # Broadcast A to full resolution\n",
    "        A_b = A.expand(-1, -1, H, W)\n",
    "        \n",
    "        # ===== INVERT THE IMAGING MODEL (NO DATA LEAK) =====\n",
    "        # Forward model: I_cam = I_clean * t + A * (1 - t)\n",
    "        # Inverted model: I_clean = (I_cam - A * (1 - t)) / t\n",
    "        numerator = I_cam_l - A_b * (1 - t)\n",
    "        denominator = torch.maximum(t, torch.tensor(self.t_min, device=t.device))\n",
    "        I_hat_l = numerator / denominator\n",
    "        I_hat_l = clamp01(I_hat_l)\n",
    "        # ===================================================\n",
    "        \n",
    "        # Forward projection (only if ground truth available, for physics loss)\n",
    "        I_phys_l = None\n",
    "        if \"I_clean_lin\" in batch:\n",
    "            I_ref_l = batch[\"I_clean_lin\"].to(DEVICE)\n",
    "            I_phys_l = I_ref_l * t + A_b * (1 - t)\n",
    "        \n",
    "        return {\n",
    "            \"I_hat_lin\": I_hat_l,      # Predicted clean image (from inversion)\n",
    "            \"I_phys_lin\": I_phys_l,    # Forward projection (for regularization)\n",
    "            \"t\": t,\n",
    "            \"A\": A,\n",
    "            \"zw\": zw,\n",
    "            \"sigma2\": sigma2\n",
    "        }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EMA\n",
    "# ============================================================================\n",
    "\n",
    "class EMA:\n",
    "    \"\"\"Exponential Moving Average for model parameters\"\"\"\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.ema = {k: v.detach().clone().float() for k, v in model.state_dict().items()}\n",
    "        self.decay = decay\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def update(self, model):\n",
    "        sd = model.state_dict()\n",
    "        for k in self.ema.keys():\n",
    "            self.ema[k].mul_(self.decay).add_(sd[k].detach().float(), alpha=1 - self.decay)\n",
    "    \n",
    "    def copy_to(self, model):\n",
    "        model.load_state_dict(self.ema, strict=True)\n",
    "\n",
    "# ============================================================================\n",
    "# LOSSES\n",
    "# ============================================================================\n",
    "\n",
    "def ssim_srgb(x, y, C1=0.01**2, C2=0.03**2):\n",
    "    \"\"\"SSIM in sRGB space\"\"\"\n",
    "    mu_x = F.avg_pool2d(x, 11, stride=1, padding=5)\n",
    "    mu_y = F.avg_pool2d(y, 11, stride=1, padding=5)\n",
    "    sigma_x = F.avg_pool2d(x*x, 11, 1, 5) - mu_x*mu_x\n",
    "    sigma_y = F.avg_pool2d(y*y, 11, 1, 5) - mu_y*mu_y\n",
    "    sigma_xy = F.avg_pool2d(x*y, 11, 1, 5) - mu_x*mu_y\n",
    "    ssim_n = (2*mu_x*mu_y + C1) * (2*sigma_xy + C2)\n",
    "    ssim_d = (mu_x*mu_x + mu_y*mu_y + C1) * (sigma_x + sigma_y + C2)\n",
    "    ssim_map = ssim_n / (ssim_d + 1e-8)\n",
    "    return ssim_map.mean()\n",
    "\n",
    "def psnr_srgb(x, y):\n",
    "    \"\"\"PSNR in sRGB space\"\"\"\n",
    "    mse = F.mse_loss(x, y)\n",
    "    return 10 * torch.log10(1.0 / (mse + 1e-8))\n",
    "\n",
    "def tv_loss_t(t):\n",
    "    \"\"\"Total variation loss for transmission map\"\"\"\n",
    "    dx = t[:, :, :, 1:] - t[:, :, :, :-1]\n",
    "    dy = t[:, :, 1:, :] - t[:, :, :-1, :]\n",
    "    return (dx.abs().mean() + dy.abs().mean())\n",
    "\n",
    "def A_prior_loss(A, I_cam_lin):\n",
    "    \"\"\"Atmospheric light should be close to mean of camera input\"\"\"\n",
    "    mean_cam = I_cam_lin.mean(dim=(2, 3), keepdim=True)\n",
    "    return F.mse_loss(A, mean_cam)\n",
    "\n",
    "def heteroscedastic_l1(err_lin, sigma2):\n",
    "    \"\"\"Heteroscedastic L1 loss\"\"\"\n",
    "    eps = 1e-6\n",
    "    return ((err_lin / (sigma2 + eps)) + torch.log(sigma2 + eps)).mean()\n",
    "\n",
    "def compute_losses(batch, out, epoch, hetero_on):\n",
    "    \"\"\"Compute all losses for physics-only model (CORRECTED)\"\"\"\n",
    "    W = CFG[\"loss\"][\"weights\"]\n",
    "    \n",
    "    # Get tensors\n",
    "    I_hat_l = out[\"I_hat_lin\"]       # Predicted clean image\n",
    "    I_phys_l = out[\"I_phys_lin\"]     # Forward projection (can be None)\n",
    "    I_cam_l = batch[\"I_cam_lin\"].to(DEVICE)\n",
    "    I_ref_l = batch[\"I_clean_lin\"].to(DEVICE)\n",
    "    \n",
    "    # ===== MAIN LOSS: Reconstruction =====\n",
    "    # Compare predicted clean with ground truth clean\n",
    "    L_recon = F.l1_loss(I_hat_l, I_ref_l)\n",
    "    \n",
    "    # ===== REGULARIZATION: Physics consistency =====\n",
    "    # Forward projection should match camera input\n",
    "    L_phys = torch.tensor(0., device=DEVICE)\n",
    "    if I_phys_l is not None:\n",
    "        L_phys = F.l1_loss(I_phys_l, I_cam_l)\n",
    "    \n",
    "    # ===== REGULARIZATION: Transmission smoothness =====\n",
    "    L_tv = tv_loss_t(out[\"t\"])\n",
    "    \n",
    "    # ===== REGULARIZATION: Atmospheric light prior =====\n",
    "    L_Ap = A_prior_loss(out[\"A\"], I_cam_l)\n",
    "    \n",
    "    # ===== UNCERTAINTY: Heteroscedastic loss =====\n",
    "    hetero_loss = torch.tensor(0., device=DEVICE)\n",
    "    if hetero_on:\n",
    "        err = (I_hat_l - I_ref_l).abs()  # Error in predicted clean\n",
    "        hetero_loss = heteroscedastic_l1(err, out[\"sigma2\"])\n",
    "    \n",
    "    # ===== TOTAL LOSS =====\n",
    "    # Main reconstruction loss + weighted regularization terms\n",
    "    loss = L_recon + W[\"phys\"] * L_phys + W[\"tv_t\"] * L_tv + W[\"A_prior\"] * L_Ap\n",
    "    \n",
    "    if hetero_on:\n",
    "        loss = loss + CFG[\"schedules\"][\"hetero\"][\"weight\"] * hetero_loss\n",
    "    \n",
    "    # ===== LOGGING =====\n",
    "    logs = {\n",
    "        \"L_total\": loss.item(),\n",
    "        \"Recon\": L_recon.item(),      # Main loss\n",
    "        \"Phys\": L_phys.item(),         # Physics regularization\n",
    "        \"TVt\": L_tv.item(),            # TV regularization\n",
    "        \"Apr\": L_Ap.item(),            # Prior regularization\n",
    "        \"Hetero\": hetero_loss.item() if hetero_on else 0.0\n",
    "    }\n",
    "    \n",
    "    return loss, logs\n",
    "# ============================================================================\n",
    "# TRAINING UTILITIES\n",
    "# ============================================================================\n",
    "\n",
    "class HeteroWatchdog:\n",
    "    \"\"\"Watchdog for heteroscedastic uncertainty\"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        wd = cfg[\"loss\"][\"heteroscedastic\"][\"watchdog\"]\n",
    "        self.th = wd[\"mean_sigma2_thresh\"]\n",
    "        self.req = wd[\"over_thresh_required\"]\n",
    "        self.cool = wd[\"cooldown_epochs\"]\n",
    "        self.count = 0\n",
    "        self.cooldown = 0\n",
    "    \n",
    "    def update(self, mean_sigma2):\n",
    "        if mean_sigma2 > self.th:\n",
    "            self.count += 1\n",
    "        else:\n",
    "            self.count = 0\n",
    "        \n",
    "        triggered = False\n",
    "        if self.count >= self.req:\n",
    "            self.cooldown = self.cool\n",
    "            self.count = 0\n",
    "            triggered = True\n",
    "        \n",
    "        if self.cooldown > 0:\n",
    "            self.cooldown -= 1\n",
    "            return False, True  # hetero disabled during cooldown\n",
    "        \n",
    "        return triggered, False\n",
    "\n",
    "def cosine_lr(optimizer, step, total_steps, base_lr, min_lr, warmup_steps):\n",
    "    \"\"\"Cosine learning rate schedule with warmup\"\"\"\n",
    "    if step < warmup_steps:\n",
    "        lr = base_lr * step / max(1, warmup_steps)\n",
    "    else:\n",
    "        t = (step - warmup_steps) / max(1, total_steps - warmup_steps)\n",
    "        lr = min_lr + 0.5 * (base_lr - min_lr) * (1 + math.cos(math.pi * t))\n",
    "    \n",
    "    for pg in optimizer.param_groups:\n",
    "        pg[\"lr\"] = lr\n",
    "    \n",
    "    return lr\n",
    "\n",
    "def save_checkpoint(state_dict, path):\n",
    "    \"\"\"Save checkpoint to disk\"\"\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    # Move to CPU before saving\n",
    "    cpu_state = {k: v.cpu().clone() for k, v in state_dict.items()}\n",
    "    torch.save(cpu_state, path)\n",
    "    print(f\"✓ Saved: {path}\")\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "def train_val_setup():\n",
    "    \"\"\"Initialize model, optimizer, and data loaders\"\"\"\n",
    "    dl_train, dl_val, dl_test = get_loaders(CFG)\n",
    "    model = TRIDENT(CFG).to(DEVICE)\n",
    "    \n",
    "    opt = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=CFG[\"schedules\"][\"lr\"][\"base\"],\n",
    "        betas=tuple(CFG[\"optimizer\"][\"betas\"]),\n",
    "        weight_decay=CFG[\"optimizer\"][\"weight_decay\"]\n",
    "    )\n",
    "    \n",
    "    scaler = torch.amp.GradScaler('cuda', enabled=(CFG[\"amp\"] and DEVICE.startswith(\"cuda\")))\n",
    "    ema = EMA(model, decay=CFG[\"ema\"][\"decay\"]) if CFG[\"ema\"][\"enabled\"] else None\n",
    "    \n",
    "    return model, opt, scaler, ema, dl_train, dl_val, dl_test\n",
    "\n",
    "def run_training():\n",
    "    \"\"\"Main training loop\"\"\"\n",
    "    import gc\n",
    "    \n",
    "    model, opt, scaler, ema, dl_train, dl_val, dl_test = train_val_setup()\n",
    "    steps_per_epoch = len(dl_train)\n",
    "    total_steps = steps_per_epoch * CFG[\"schedules\"][\"epochs\"]\n",
    "    hetero_wd = HeteroWatchdog(CFG)\n",
    "    \n",
    "    best_ssim = -1.0\n",
    "    best_l1 = float('inf')\n",
    "    step = 0\n",
    "    \n",
    "    for epoch in range(1, CFG[\"schedules\"][\"epochs\"] + 1):\n",
    "        # Memory cleanup\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        epoch_logs = []\n",
    "        pbar = tqdm(dl_train, desc=f\"Epoch {epoch}/{CFG['schedules']['epochs']} [train]\", leave=True)\n",
    "        \n",
    "        for b, batch in enumerate(pbar):\n",
    "            lr = cosine_lr(opt, step, total_steps,\n",
    "                          CFG[\"schedules\"][\"lr\"][\"base\"],\n",
    "                          CFG[\"schedules\"][\"lr\"][\"min\"],\n",
    "                          CFG[\"schedules\"][\"warmup_steps\"])\n",
    "            \n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            \n",
    "            # Forward pass with AMP\n",
    "            ctx = torch.amp.autocast('cuda', enabled=(CFG[\"amp\"] and DEVICE.startswith(\"cuda\")))\n",
    "            with ctx:\n",
    "                out = model(batch)\n",
    "                hetero_on = (epoch >= CFG[\"schedules\"][\"hetero\"][\"start_epoch\"]) and (hetero_wd.cooldown == 0)\n",
    "                loss, logs = compute_losses(batch, out, epoch, hetero_on)\n",
    "            \n",
    "            # Backward pass\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG[\"optimizer\"][\"grad_clip\"])\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "            \n",
    "            if CFG[\"ema\"][\"enabled\"]:\n",
    "                ema.update(model)\n",
    "            \n",
    "            epoch_logs.append(logs)\n",
    "            step += 1\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                \"lr\": f\"{lr:.2e}\",\n",
    "                \"L\": f\"{logs['L_total']:.3f}\",\n",
    "                \"Recon\": f\"{logs['Recon']:.3f}\",\n",
    "                \"Phys\": f\"{logs['Phys']:.3f}\"\n",
    "            })\n",
    "            \n",
    "            # Periodic memory cleanup\n",
    "            if step % 200 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        # Memory cleanup before validation\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_model = TRIDENT(CFG).to(DEVICE)\n",
    "        if CFG[\"ema\"][\"enabled\"]:\n",
    "            ema.copy_to(val_model)\n",
    "        else:\n",
    "            val_model.load_state_dict(model.state_dict())\n",
    "        val_model.eval()\n",
    "        \n",
    "        ssim_vals, l1_vals, sigma_means = [], [], []\n",
    "        pbar_val = tqdm(dl_val, desc=f\"Epoch {epoch} [val]\", leave=False)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in pbar_val:\n",
    "                out = val_model(batch)\n",
    "                I_hat_s = to_srgb(out[\"I_hat_lin\"], CFG[\"model\"][\"colorspace\"][\"gamma\"])\n",
    "                I_ref_s = to_srgb(batch[\"I_clean_lin\"].to(DEVICE), CFG[\"model\"][\"colorspace\"][\"gamma\"])\n",
    "                \n",
    "                ssim_vals.append(ssim_srgb(I_hat_s, I_ref_s).item())\n",
    "                l1_vals.append(F.l1_loss(out[\"I_hat_lin\"], batch[\"I_clean_lin\"].to(DEVICE)).item())\n",
    "                sigma_means.append(out[\"sigma2\"].mean().item())\n",
    "                \n",
    "                pbar_val.set_postfix({\n",
    "                    \"SSIM\": f\"{np.mean(ssim_vals):.3f}\",\n",
    "                    \"L1\": f\"{np.mean(l1_vals):.3f}\"\n",
    "                })\n",
    "        \n",
    "        val_ssim = float(np.mean(ssim_vals))\n",
    "        val_l1 = float(np.mean(l1_vals))\n",
    "        mean_sigma = float(np.mean(sigma_means))\n",
    "        \n",
    "        # Delete validation model\n",
    "        del val_model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        # Watchdog updates\n",
    "        trig, disabled = hetero_wd.update(mean_sigma)\n",
    "        \n",
    "        # Save best models immediately\n",
    "        if val_ssim > best_ssim:\n",
    "            best_ssim = val_ssim\n",
    "            print(f\"  → New best SSIM: {val_ssim:.4f}\")\n",
    "            if CFG[\"ema\"][\"enabled\"]:\n",
    "                save_checkpoint(ema.ema, \"checkpointsphy/best_ssim.pt\")\n",
    "            else:\n",
    "                save_checkpoint(model.state_dict(), \"checkpointsphy/best_ssim.pt\")\n",
    "        \n",
    "        if val_l1 < best_l1:\n",
    "            best_l1 = val_l1\n",
    "            print(f\"  → New best L1: {val_l1:.4f}\")\n",
    "            if CFG[\"ema\"][\"enabled\"]:\n",
    "                save_checkpoint(ema.ema, \"checkpointsphy/best_l1.pt\")\n",
    "            else:\n",
    "                save_checkpoint(model.state_dict(), \"checkpointsphy/best_l1.pt\")\n",
    "        \n",
    "        print(f\"[Epoch {epoch}] SSIM={val_ssim:.4f}  L1={val_l1:.4f}  \"\n",
    "              f\"meanσ²={mean_sigma:.3f}  heteroCooldown={hetero_wd.cooldown}\")\n",
    "    \n",
    "    # Save final checkpoint\n",
    "    save_checkpoint(model.state_dict(), \"checkpointsphy/last.pt\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"Training complete!\")\n",
    "    print(f\"Best SSIM: {best_ssim:.4f}\")\n",
    "    print(f\"Best L1: {best_l1:.4f}\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# VERIFICATION: Test that no data leak exists\n",
    "# ============================================================================\n",
    "\n",
    "def verify_no_data_leak():\n",
    "    \"\"\"\n",
    "    Verify that the model can run inference without ground truth\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Verifying No Data Leak\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Create model\n",
    "    model = TRIDENT(CFG).to(DEVICE)\n",
    "    model.eval()\n",
    "    \n",
    "    # Create dummy input (NO GROUND TRUTH)\n",
    "    dummy_cam_srgb = torch.rand(2, 3, 256, 256)\n",
    "    dummy_cam_lin = to_linear(dummy_cam_srgb, CFG[\"model\"][\"colorspace\"][\"gamma\"])\n",
    "    \n",
    "    dummy_batch = {\n",
    "        \"I_cam_lin\": dummy_cam_lin\n",
    "        # Note: NO \"I_clean_lin\" key!\n",
    "    }\n",
    "    \n",
    "    # Test forward pass\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            output = model(dummy_batch)\n",
    "        \n",
    "        print(\"✓ Model runs without ground truth!\")\n",
    "        print(f\"  Output keys: {list(output.keys())}\")\n",
    "        print(f\"  I_hat shape: {output['I_hat_lin'].shape}\")\n",
    "        print(f\"  t shape: {output['t'].shape}\")\n",
    "        print(f\"  A shape: {output['A'].shape}\")\n",
    "        \n",
    "        # Check that I_phys_lin is None (since no ground truth)\n",
    "        if output['I_phys_lin'] is None:\n",
    "            print(\"✓ I_phys_lin is None (expected, no ground truth)\")\n",
    "        \n",
    "        # Check value ranges\n",
    "        print(f\"\\nValue ranges:\")\n",
    "        print(f\"  I_hat: [{output['I_hat_lin'].min():.3f}, {output['I_hat_lin'].max():.3f}]\")\n",
    "        print(f\"  t: [{output['t'].min():.3f}, {output['t'].max():.3f}]\")\n",
    "        print(f\"  A: [{output['A'].min():.3f}, {output['A'].max():.3f}]\")\n",
    "        \n",
    "        print(\"\\n✓ Verification passed! No data leak detected.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Verification failed: {e}\")\n",
    "        print(\"  Make sure you've replaced the TRIDENT class with the corrected version.\")\n",
    "    \n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EVALUATION & EXPORT\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_and_export():\n",
    "    \"\"\"Evaluate on test set and export results\"\"\"\n",
    "    # Load best SSIM model\n",
    "    model = TRIDENT(CFG).to(DEVICE)\n",
    "    \n",
    "    checkpoint_path = \"checkpointsphy/last2.pt\"\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(f\"[ERROR] Checkpoint not found: {checkpoint_path}\")\n",
    "        return\n",
    "    \n",
    "    sd = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "    model.load_state_dict(sd, strict=True)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Loaded checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "    _, _, dl_test = get_loaders(CFG)\n",
    "    \n",
    "    # Create export directories\n",
    "    base_export_dir = CFG[\"logging\"][\"export_test\"][\"dir\"]\n",
    "    os.makedirs(base_export_dir, exist_ok=True)\n",
    "    \n",
    "    if CFG[\"logging\"][\"export_test\"].get(\"save_images\", False):\n",
    "        img_export_dir = os.path.join(base_export_dir, \"images\")\n",
    "        os.makedirs(img_export_dir, exist_ok=True)\n",
    "    \n",
    "    SSIMs, PSNRs, L1s = [], [], []\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EVALUATION ON TEST SET\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(tqdm(dl_test, desc=\"Evaluating and Exporting\")):\n",
    "            out = model(batch)\n",
    "            I_hat_s = to_srgb(out[\"I_hat_lin\"], CFG[\"model\"][\"colorspace\"][\"gamma\"])\n",
    "            I_ref_s = to_srgb(batch[\"I_clean_lin\"].to(DEVICE), CFG[\"model\"][\"colorspace\"][\"gamma\"])\n",
    "            \n",
    "            # --- Image Saving Logic ---\n",
    "            if CFG[\"logging\"][\"export_test\"].get(\"save_images\", False):\n",
    "                I_cam_s = batch[\"I_cam_srgb\"].to(DEVICE)\n",
    "                cam_paths = batch[\"cam_path\"]\n",
    "                \n",
    "                # Save each image in the batch individually\n",
    "                for i in range(I_hat_s.shape[0]):\n",
    "                    base_name = os.path.basename(cam_paths[i])\n",
    "                    \n",
    "                    # Create side-by-side comparison: [Input | Output | Ground Truth]\n",
    "                    comparison_grid = torch.cat([I_cam_s[i], I_hat_s[i], I_ref_s[i]], dim=-1)\n",
    "                    \n",
    "                    # Save comparison image\n",
    "                    save_path = os.path.join(img_export_dir, base_name)\n",
    "                    from torchvision.utils import save_image\n",
    "                    save_image(comparison_grid, save_path)\n",
    "            \n",
    "            # --- Metric Calculation ---\n",
    "            SSIMs.append(ssim_srgb(I_hat_s, I_ref_s).item())\n",
    "            PSNRs.append(psnr_srgb(I_hat_s, I_ref_s).item())\n",
    "            L1s.append(F.l1_loss(out[\"I_hat_lin\"], batch[\"I_clean_lin\"].to(DEVICE)).item())\n",
    "            \n",
    "            # --- Physics Export Logic ---\n",
    "            if CFG[\"logging\"][\"export_test\"][\"tAzw\"]:\n",
    "                # Save one .npz file per batch\n",
    "                batch_id = os.path.basename(batch[\"cam_path\"][0]).split('.')[0]\n",
    "                np.savez_compressed(\n",
    "                    os.path.join(base_export_dir, f\"physics_{batch_id}.npz\"),\n",
    "                    t=out[\"t\"].detach().cpu().numpy(),\n",
    "                    A=out[\"A\"].detach().cpu().numpy(),\n",
    "                    zw=out[\"zw\"].detach().cpu().numpy(),\n",
    "                    sigma2=out[\"sigma2\"].detach().cpu().numpy()\n",
    "                )\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TEST RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"SSIM:  {np.mean(SSIMs):.4f} ± {np.std(SSIMs):.4f}\")\n",
    "    print(f\"PSNR:  {np.mean(PSNRs):.2f} ± {np.std(PSNRs):.2f} dB\")\n",
    "    print(f\"L1:    {np.mean(L1s):.4f} ± {np.std(L1s):.4f}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Save metrics to JSON\n",
    "    metrics = {\n",
    "        \"ssim_mean\": float(np.mean(SSIMs)),\n",
    "        \"ssim_std\": float(np.std(SSIMs)),\n",
    "        \"psnr_mean\": float(np.mean(PSNRs)),\n",
    "        \"psnr_std\": float(np.std(PSNRs)),\n",
    "        \"l1_mean\": float(np.mean(L1s)),\n",
    "        \"l1_std\": float(np.std(L1s))\n",
    "    }\n",
    "    \n",
    "    metrics_path = os.path.join(base_export_dir, \"test_metrics.json\")\n",
    "    with open(metrics_path, 'w') as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n✓ Metrics saved to: {metrics_path}\")\n",
    "    \n",
    "    if CFG[\"logging\"][\"export_test\"].get(\"save_images\", False):\n",
    "        print(f\"✓ Images saved to: {img_export_dir}\")\n",
    "    \n",
    "    if CFG[\"logging\"][\"export_test\"][\"tAzw\"]:\n",
    "        print(f\"✓ Physics parameters saved to: {base_export_dir}\")\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TRIDENT PHYSICS-ONLY MODEL\")\n",
    "    print(\"Underwater Image Restoration via Physics-Based Approach\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    verify_no_data_leak()\n",
    "    # Check if we should run training or just evaluation\n",
    "    if len(sys.argv) > 1 and sys.argv[1] == \"eval\":\n",
    "        print(\"Running evaluation only...\\n\")\n",
    "        evaluate_and_export()\n",
    "    else:\n",
    "        print(\"Starting training...\\n\")\n",
    "        run_training()\n",
    "        print(\"\\nStarting evaluation...\\n\")\n",
    "        evaluate_and_export()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ALL DONE!\")\n",
    "    print(\"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint: checkpointsphy/last2.pt\n",
      "\n",
      "======================================================================\n",
      "EVALUATION ON TEST SET\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52f65d1eeb342fb8a8c2cacd92f70e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating and Exporting:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TEST RESULTS\n",
      "======================================================================\n",
      "SSIM:  0.8385 ± 0.0181\n",
      "PSNR:  20.40 ± 0.95 dB\n",
      "L1:    0.0528 ± 0.0068\n",
      "======================================================================\n",
      "\n",
      "✓ Metrics saved to: outputs/test_exports\\test_metrics.json\n",
      "✓ Images saved to: outputs/test_exports\\images\n",
      "✓ Physics parameters saved to: outputs/test_exports\n"
     ]
    }
   ],
   "source": [
    "evaluate_and_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
