{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.18","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":105399,"databundleVersionId":12733338,"sourceType":"competition"}],"dockerImageVersionId":31091,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U xgboost polars optuna catboost lightgbm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-15T12:14:25.525424Z","iopub.execute_input":"2025-08-15T12:14:25.525809Z","iopub.status.idle":"2025-08-15T12:14:33.315719Z","shell.execute_reply.started":"2025-08-15T12:14:25.525783Z","shell.execute_reply":"2025-08-15T12:14:33.310675Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: xgboost in /usr/local/lib/python3.10/site-packages (3.0.4)\nRequirement already satisfied: polars in /usr/local/lib/python3.10/site-packages (1.32.3)\nRequirement already satisfied: optuna in /usr/local/lib/python3.10/site-packages (4.4.0)\nRequirement already satisfied: catboost in /usr/local/lib/python3.10/site-packages (1.2.8)\nRequirement already satisfied: lightgbm in /usr/local/lib/python3.10/site-packages (4.6.0)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (from xgboost) (1.15.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from xgboost) (2.0.2)\nRequirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/site-packages (from xgboost) (2.21.5)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from optuna) (25.0)\nRequirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/site-packages (from optuna) (1.16.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from optuna) (4.67.1)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/site-packages (from optuna) (6.0.2)\nRequirement already satisfied: colorlog in /usr/local/lib/python3.10/site-packages (from optuna) (6.9.0)\nRequirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/site-packages (from optuna) (2.0.43)\nRequirement already satisfied: plotly in /usr/local/lib/python3.10/site-packages (from catboost) (6.3.0)\nRequirement already satisfied: graphviz in /usr/local/lib/python3.10/site-packages (from catboost) (0.21)\nRequirement already satisfied: six in /usr/local/lib/python3.10/site-packages (from catboost) (1.17.0)\nRequirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/site-packages (from catboost) (2.3.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (from catboost) (3.10.3)\nRequirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.14.0)\nRequirement already satisfied: tomli in /usr/local/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (2.2.1)\nRequirement already satisfied: Mako in /usr/local/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.10)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2025.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2025.2)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.10/site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib->catboost) (0.12.1)\nRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib->catboost) (11.3.0)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib->catboost) (4.58.4)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib->catboost) (1.3.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib->catboost) (3.2.3)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.8)\nRequirement already satisfied: narwhals>=1.15.1 in /usr/local/lib/python3.10/site-packages (from plotly->catboost) (2.1.2)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport polars as pl\nfrom sklearn.model_selection import GroupShuffleSplit\nimport pickle\nimport gc\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Constants\nRANDOM_STATE = 42\nnp.random.seed(RANDOM_STATE)\n\nprint(\"Loading raw data...\")\n# Load data using polars for efficiency\ntrain = pl.read_parquet('/kaggle/input/aeroclub-recsys-2025/train.parquet').drop('__index_level_0__')\ntest = pl.read_parquet('/kaggle/input/aeroclub-recsys-2025/test.parquet').drop('__index_level_0__').with_columns(pl.lit(0, dtype=pl.Int64).alias(\"selected\"))\n\ndata_raw = pl.concat((train, test))\n\nprint(f\"Train shape: {train.shape}, Test shape: {test.shape}\")\nprint(f\"Unique ranker_ids in train: {train['ranker_id'].n_unique():,}\")\nprint(f\"Selected rate: {train['selected'].mean():.3f}\")\n\ndef dur_to_min(col):\n    \"\"\"More efficient duration to minutes converter\"\"\"\n    # Extract days and time parts in one pass\n    days = col.str.extract(r\"^(\\d+)\\.\", 1).cast(pl.Int64).fill_null(0) * 1440\n    time_str = pl.when(col.str.contains(r\"^\\d+\\.\")).then(col.str.replace(r\"^\\d+\\.\", \"\")).otherwise(col)\n    hours = time_str.str.extract(r\"^(\\d+):\", 1).cast(pl.Int64).fill_null(0) * 60\n    minutes = time_str.str.extract(r\":(\\d+):\", 1).cast(pl.Int64).fill_null(0)\n    return (days + hours + minutes).fill_null(0)\n\nprint(\"Starting feature engineering...\")\ndf = data_raw.clone()\n\n# Process duration columns\ndur_cols = [\"legs0_duration\", \"legs1_duration\"] + [f\"legs{l}_segments{s}_duration\" for l in (0, 1) for s in (0, 1)]\ndur_exprs = [dur_to_min(pl.col(c)).alias(c) for c in dur_cols if c in df.columns]\n\n# Apply duration transformations first\nif dur_exprs:\n    df = df.with_columns(dur_exprs)\n\n# Precompute marketing carrier columns check\nmc_cols = [f'legs{l}_segments{s}_marketingCarrier_code' for l in (0, 1) for s in range(4)]\nmc_exists = [col for col in mc_cols if col in df.columns]\n\n# Combine all initial transformations\ndf = df.with_columns([\n    # Price features\n    (pl.col(\"totalPrice\") / (pl.col(\"taxes\") + 1)).alias(\"price_per_tax\"),\n    (pl.col(\"taxes\") / (pl.col(\"totalPrice\") + 1)).alias(\"tax_rate\"),\n    pl.col(\"totalPrice\").log1p().alias(\"log_price\"),\n    \n    # Duration features\n    (pl.col(\"legs0_duration\").fill_null(0) + pl.col(\"legs1_duration\").fill_null(0)).alias(\"total_duration\"),\n    pl.when(pl.col(\"legs1_duration\").fill_null(0) > 0)\n        .then(pl.col(\"legs0_duration\") / (pl.col(\"legs1_duration\") + 1))\n        .otherwise(1.0).alias(\"duration_ratio\"),\n    \n    # Trip type\n    (pl.col(\"legs1_duration\").is_null() | \n     (pl.col(\"legs1_duration\") == 0) | \n     pl.col(\"legs1_segments0_departureFrom_airport_iata\").is_null()).cast(pl.Int32).alias(\"is_one_way\"),\n    \n    # Total segments count\n    (pl.sum_horizontal(pl.col(col).is_not_null().cast(pl.UInt8) for col in mc_exists) \n     if mc_exists else pl.lit(0)).alias(\"l0_seg\"),\n    \n    # FF features\n    (pl.col(\"frequentFlyer\").fill_null(\"\").str.count_matches(\"/\") + \n     (pl.col(\"frequentFlyer\").fill_null(\"\") != \"\").cast(pl.Int32)).alias(\"n_ff_programs\"),\n    \n    # Binary features\n    pl.col(\"corporateTariffCode\").is_not_null().cast(pl.Int32).alias(\"has_corporate_tariff\"),\n    (pl.col(\"pricingInfo_isAccessTP\") == 1).cast(pl.Int32).alias(\"has_access_tp\"),\n    \n    # Cancellation/Exchange rules\n    (\n        (pl.col(\"miniRules0_monetaryAmount\") == 0)\n        & (pl.col(\"miniRules0_statusInfos\") == 1)\n    ).cast(pl.Int8).alias(\"free_cancel\"),\n    (\n        (pl.col(\"miniRules1_monetaryAmount\") == 0)\n        & (pl.col(\"miniRules1_statusInfos\") == 1)\n    ).cast(pl.Int8).alias(\"free_exchange\"),\n\n    # Routes & carriers\n    pl.col(\"searchRoute\").is_in([\"MOWLED/LEDMOW\", \"LEDMOW/MOWLED\", \"MOWLED\", \"LEDMOW\"])\n        .cast(pl.Int32).alias(\"is_popular_route\"),\n    \n    # Cabin\n    pl.mean_horizontal([\"legs0_segments0_cabinClass\", \"legs1_segments0_cabinClass\"]).alias(\"avg_cabin_class\"),\n    (pl.col(\"legs0_segments0_cabinClass\").fill_null(0) - \n     pl.col(\"legs1_segments0_cabinClass\").fill_null(0)).alias(\"cabin_class_diff\"),\n])\n\n# Segment counts - more efficient\nseg_exprs = []\nfor leg in (0, 1):\n    seg_cols = [f\"legs{leg}_segments{s}_duration\" for s in range(4) if f\"legs{leg}_segments{s}_duration\" in df.columns]\n    if seg_cols:\n        seg_exprs.append(\n            pl.sum_horizontal(pl.col(c).is_not_null() for c in seg_cols)\n                .cast(pl.Int32).alias(f\"n_segments_leg{leg}\")\n        )\n    else:\n        seg_exprs.append(pl.lit(0).cast(pl.Int32).alias(f\"n_segments_leg{leg}\"))\n\n# Add segment-based features\ndf = df.with_columns(seg_exprs)\n\n# Then use them for derived features\ndf = df.with_columns([\n    (pl.col(\"n_segments_leg0\") + pl.col(\"n_segments_leg1\")).alias(\"total_segments\"),\n    (pl.col(\"n_segments_leg0\") == 1).cast(pl.Int32).alias(\"is_direct_leg0\"),\n    pl.when(pl.col(\"is_one_way\") == 1).then(0)\n        .otherwise((pl.col(\"n_segments_leg1\") == 1).cast(pl.Int32)).alias(\"is_direct_leg1\"),\n])\n\n# More derived features\ndf = df.with_columns([\n    (pl.col(\"is_direct_leg0\") & pl.col(\"is_direct_leg1\")).cast(pl.Int32).alias(\"both_direct\"),\n    ((pl.col(\"isVip\") == 1) | (pl.col(\"n_ff_programs\") > 0)).cast(pl.Int32).alias(\"is_vip_freq\"),\n    pl.col(\"Id\").count().over(\"ranker_id\").alias(\"group_size\"),\n])\n\n# Add major carrier flag if column exists\nif \"legs0_segments0_marketingCarrier_code\" in df.columns:\n    df = df.with_columns(\n        pl.col(\"legs0_segments0_marketingCarrier_code\").is_in([\"SU\", \"S7\"])\n            .cast(pl.Int32).alias(\"is_major_carrier\")\n    )\nelse:\n    df = df.with_columns(pl.lit(0).alias(\"is_major_carrier\"))\n\ndf = df.with_columns(pl.col(\"group_size\").log1p().alias(\"group_size_log\"))\n\n# Time features - batch process\ntime_exprs = []\nfor col in (\"legs0_departureAt\", \"legs0_arrivalAt\", \"legs1_departureAt\", \"legs1_arrivalAt\"):\n    if col in df.columns:\n        dt = pl.col(col).str.to_datetime(strict=False)\n        h = dt.dt.hour().fill_null(12)\n        time_exprs.extend([\n            h.alias(f\"{col}_hour\"),\n            dt.dt.weekday().fill_null(0).alias(f\"{col}_weekday\"),\n            (((h >= 6) & (h <= 9)) | ((h >= 17) & (h <= 20))).cast(pl.Int32).alias(f\"{col}_business_time\")\n        ])\nif time_exprs:\n    df = df.with_columns(time_exprs)\n\n# Price and duration basic ranks\nrank_exprs = []\nfor col, alias in [(\"totalPrice\", \"price\"), (\"total_duration\", \"duration\")]:\n    rank_exprs.append(pl.col(col).rank().over(\"ranker_id\").alias(f\"{alias}_rank\"))\n\n# Price-specific features\nprice_exprs = [\n    (pl.col(\"totalPrice\").rank(\"average\").over(\"ranker_id\") / \n     pl.col(\"totalPrice\").count().over(\"ranker_id\")).alias(\"price_pct_rank\"),\n    (pl.col(\"totalPrice\") == pl.col(\"totalPrice\").min().over(\"ranker_id\")).cast(pl.Int32).alias(\"is_cheapest\"),\n    ((pl.col(\"totalPrice\") - pl.col(\"totalPrice\").median().over(\"ranker_id\")) / \n     (pl.col(\"totalPrice\").std().over(\"ranker_id\") + 1)).alias(\"price_from_median\"),\n    (pl.col(\"l0_seg\") == pl.col(\"l0_seg\").min().over(\"ranker_id\")).cast(pl.Int32).alias(\"is_min_segments\"),\n]\n\n# Apply initial ranks\ndf = df.with_columns(rank_exprs + price_exprs)\n\n# Cheapest direct - more efficient\ndirect_cheapest = (\n    df.filter(pl.col(\"is_direct_leg0\") == 1)\n    .group_by(\"ranker_id\")\n    .agg(pl.col(\"totalPrice\").min().alias(\"min_direct\"))\n)\n\ndf = df.join(direct_cheapest, on=\"ranker_id\", how=\"left\").with_columns(\n    ((pl.col(\"is_direct_leg0\") == 1) & \n     (pl.col(\"totalPrice\") == pl.col(\"min_direct\"))).cast(pl.Int32).fill_null(0).alias(\"is_direct_cheapest\")\n).drop(\"min_direct\")\n\n# Popularity features - efficient join\ndf = (\n    df.join(\n        train.group_by('legs0_segments0_marketingCarrier_code').agg(pl.mean('selected').alias('carrier0_pop')),\n        on='legs0_segments0_marketingCarrier_code', \n        how='left'\n    )\n    .join(\n        train.group_by('legs1_segments0_marketingCarrier_code').agg(pl.mean('selected').alias('carrier1_pop')),\n        on='legs1_segments0_marketingCarrier_code', \n        how='left'\n    )\n    .with_columns([\n        pl.col('carrier0_pop').fill_null(0.0),\n        pl.col('carrier1_pop').fill_null(0.0),\n    ])\n)\n\n# Step 1: Add independent features\ndf = df.with_columns([\n    # Carrier popularity\n    (pl.col('carrier0_pop') * pl.col('carrier1_pop')).alias('carrier_pop_product'),\n])\n\n# Business traveler and meeting-friendly features\ndf = df.with_columns([\n    (\n        # Policy compliance (25% weight)\n        (pl.col(\"pricingInfo_isAccessTP\") * 0.25) +\n        # Direct flights (25% weight)\n        (pl.col(\"is_direct_leg0\") * 0.25) +\n        # Business-hour departures/arrivals (25% weight)\n        ((pl.col(\"legs0_departureAt_business_time\") + pl.col(\"legs1_departureAt_business_time\")) * 0.125) +\n        # VIP preference for business class (25% weight)\n        ((pl.col(\"isVip\") == 1) & (pl.col(\"avg_cabin_class\") >= 1.5)).cast(pl.Int8) * 0.25\n    ).alias(\"business_traveler_perfect_match\"),\n\n    # Timezone diff only\n    (pl.col(\"legs0_arrivalAt_hour\") - pl.col(\"legs0_departureAt_hour\") -\n     (pl.col(\"legs0_duration\") / 60)).alias(\"timezone_diff_leg0\"),\n])\n\ndf = df.with_columns([\n    (\n        (pl.col(\"is_one_way\") == 0) &  # Round-trip\n        (pl.col(\"legs0_arrivalAt_hour\") >= 8) &  # Arrive by morning\n        (pl.col(\"legs1_departureAt_hour\") <= 18) &  # Return by evening\n        (pl.col(\"timezone_diff_leg0\").abs() < 3)   # Minimal jetlag\n    ).cast(pl.Int8).alias(\"meeting_friendly_itinerary\")\n])\n\n# Additional temporal features\ndf = df.with_columns([\n    # Days to departure\n    (pl.col(\"legs0_departureAt\").str.to_datetime(strict=False) - \n     pl.col(\"requestDate\")).dt.total_days().fill_null(0).alias(\"days_to_departure\"),\n    \n    pl.col(\"requestDate\").dt.month().fill_null(6).alias(\"request_month\"),\n])\n\n# Seasonal features\ndf = df.with_columns([\n    ((pl.col(\"request_month\") >= 6) & (pl.col(\"request_month\") <= 8)).cast(pl.Int8).alias(\"is_summer_travel\"),\n    ((pl.col(\"request_month\") >= 12) | (pl.col(\"request_month\") <= 2)).cast(pl.Int8).alias(\"is_winter_travel\"),\n    ((pl.col(\"request_month\").is_in([12, 1, 7, 8]))).cast(pl.Int8).alias(\"is_holiday_season\"),\n])\n\n# Baggage features\ndf = df.with_columns([\n    (pl.col(\"legs0_segments0_baggageAllowance_quantity\").fill_null(0) + \n     pl.col(\"legs1_segments0_baggageAllowance_quantity\").fill_null(0)).alias(\"baggage_total\"),\n    (pl.col(\"miniRules0_monetaryAmount\").fill_null(0) + \n     pl.col(\"miniRules1_monetaryAmount\").fill_null(0)).alias(\"total_fees\"),\n])\n\ndf = df.with_columns([\n    (pl.col(\"baggage_total\") > 0).cast(pl.Int32).alias(\"has_baggage\"),\n    (pl.col(\"total_fees\") > 0).cast(pl.Int32).alias(\"has_fees\"),\n    (pl.col(\"total_fees\") / (pl.col(\"totalPrice\") + 1)).alias(\"fee_rate\"),\n])\n\nprint(\"Feature engineering completed. Filling missing values...\")\n\n# Fill missing values\ndata = df.with_columns(\n    [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n    [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n)\n\n# Define categorical features\ncat_features = [\n    'nationality', 'searchRoute', 'corporateTariffCode',\n    'bySelf', 'sex', 'companyID',\n    # Leg 0 segments 0-1\n    'legs0_segments0_aircraft_code', 'legs0_segments0_arrivalTo_airport_city_iata',\n    'legs0_segments0_arrivalTo_airport_iata', 'legs0_segments0_departureFrom_airport_iata',\n    'legs0_segments0_marketingCarrier_code', 'legs0_segments0_operatingCarrier_code',\n    'legs0_segments0_flightNumber',\n    'legs0_segments1_aircraft_code', 'legs0_segments1_arrivalTo_airport_city_iata',\n    'legs0_segments1_arrivalTo_airport_iata', 'legs0_segments1_departureFrom_airport_iata',\n    'legs0_segments1_marketingCarrier_code', 'legs0_segments1_operatingCarrier_code',\n    'legs0_segments1_flightNumber',\n    # Leg 1 segments 0-1\n    'legs1_segments0_aircraft_code', 'legs1_segments0_arrivalTo_airport_city_iata',\n    'legs1_segments0_arrivalTo_airport_iata', 'legs1_segments0_departureFrom_airport_iata',\n    'legs1_segments0_marketingCarrier_code', 'legs1_segments0_operatingCarrier_code',\n    'legs1_segments0_flightNumber',\n    'legs1_segments1_aircraft_code', 'legs1_segments1_arrivalTo_airport_city_iata',\n    'legs1_segments1_arrivalTo_airport_iata', 'legs1_segments1_departureFrom_airport_iata',\n    'legs1_segments1_marketingCarrier_code', 'legs1_segments1_operatingCarrier_code',\n    'legs1_segments1_flightNumber'\n]\n\n# Columns to exclude (uninformative or problematic)\nexclude_cols = [\n    'Id', 'ranker_id', 'selected', 'profileId', 'requestDate',\n    'legs0_departureAt', 'legs0_arrivalAt', 'legs1_departureAt', 'legs1_arrivalAt',\n    'miniRules0_percentage', 'miniRules1_percentage',  # >90% missing\n    'frequentFlyer',  # Already processed\n    # Exclude constant columns\n    'pricingInfo_passengerCount', 'bySelf'\n]\n\n# Exclude high missing rate columns\nfor leg in [0, 1]:\n    for seg in [0, 1]:\n        if seg == 0:\n            suffixes = [\"seatsAvailable\"]\n        else:\n            suffixes = [\n                \"cabinClass\", \"seatsAvailable\", \"baggageAllowance_quantity\",\n                \"baggageAllowance_weightMeasurementType\", \"aircraft_code\",\n                \"arrivalTo_airport_city_iata\", \"arrivalTo_airport_iata\",\n                \"departureFrom_airport_iata\", \"flightNumber\",\n                \"marketingCarrier_code\", \"operatingCarrier_code\",\n            ]\n        for suffix in suffixes:\n            exclude_cols.append(f\"legs{leg}_segments{seg}_{suffix}\")\n\n# Exclude segment 2-3 columns (>98% missing)\nfor leg in [0, 1]:\n    for seg in [2, 3]:\n        for suffix in ['aircraft_code', 'arrivalTo_airport_city_iata', 'arrivalTo_airport_iata',\n                      'baggageAllowance_quantity', 'baggageAllowance_weightMeasurementType',\n                      'cabinClass', 'departureFrom_airport_iata', 'duration', 'flightNumber',\n                      'marketingCarrier_code', 'operatingCarrier_code', 'seatsAvailable']:\n            exclude_cols.append(f'legs{leg}_segments{seg}_{suffix}')\n\nfeature_cols = [col for col in data.columns if col not in exclude_cols]\ncat_features_final = [col for col in cat_features if col in feature_cols]\n\nprint(f\"Using {len(feature_cols)} features ({len(cat_features_final)} categorical)\")\n\nprint(\"Splitting data...\")\n# Convert to pandas for splitting operations\ndata_pd = data.to_pandas()\n\n# Split into train and test\nn_train = train.shape[0]\ntrain_data = data_pd.iloc[:n_train].copy()\ntest_data = data_pd.iloc[n_train:].copy()\n\n# Group-wise train/val split ensuring 85% groups in train, 15% in val\nunique_ranker_ids = train_data['ranker_id'].unique()\nn_groups = len(unique_ranker_ids)\nn_train_groups = int(n_groups * 0.85)\n\nnp.random.shuffle(unique_ranker_ids)\ntrain_groups = unique_ranker_ids[:n_train_groups]\nval_groups = unique_ranker_ids[n_train_groups:]\n\ntrain_split = train_data[train_data['ranker_id'].isin(train_groups)].copy()\nval_split = train_data[train_data['ranker_id'].isin(val_groups)].copy()\n\nprint(f\"Train split: {len(train_split):,} rows ({len(train_groups):,} groups)\")\nprint(f\"Val split: {len(val_split):,} rows ({len(val_groups):,} groups)\")\nprint(f\"Test data: {len(test_data):,} rows\")\n\n# Save processed files\nprint(\"Saving processed files...\")\ntrain_data[feature_cols + ['selected', 'ranker_id']].to_parquet('train_processed.parquet', index=False)\ntest_data[feature_cols + ['ranker_id', 'Id']].to_parquet('test_processed.parquet', index=False)\ntrain_split[feature_cols + ['selected', 'ranker_id']].to_parquet('train_split.parquet', index=False)\nval_split[feature_cols + ['selected', 'ranker_id']].to_parquet('val_split.parquet', index=False)\n\n# Save feature lists and metadata\nwith open('features.pkl', 'wb') as f:\n    pickle.dump({\n        'feature_cols': feature_cols,\n        'cat_features_final': cat_features_final,\n        'train_groups': train_groups,\n        'val_groups': val_groups\n    }, f)\n\nprint(\"✅ Data preprocessing completed successfully!\")\nprint(f\"Final dataset shape - Train: {train_data.shape}, Test: {test_data.shape}\")\nprint(f\"Features saved: {len(feature_cols)} total, {len(cat_features_final)} categorical\")\n\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T12:14:33.318552Z","iopub.execute_input":"2025-08-15T12:14:33.319264Z","iopub.status.idle":"2025-08-15T12:20:18.442543Z","shell.execute_reply.started":"2025-08-15T12:14:33.319235Z","shell.execute_reply":"2025-08-15T12:20:18.437771Z"}},"outputs":[{"name":"stdout","text":"Loading raw data...\nTrain shape: (18145372, 126), Test shape: (6897776, 126)\nUnique ranker_ids in train: 105,539\nSelected rate: 0.006\nStarting feature engineering...\nFeature engineering completed. Filling missing values...\nUsing 100 features (19 categorical)\nSplitting data...\nTrain split: 15,435,234 rows (89,708 groups)\nVal split: 2,710,138 rows (15,831 groups)\nTest data: 6,897,776 rows\nSaving processed files...\n✅ Data preprocessing completed successfully!\nFinal dataset shape - Train: (18145372, 186), Test: (6897776, 186)\nFeatures saved: 100 total, 19 categorical\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"54"},"metadata":{}}],"execution_count":4}]}